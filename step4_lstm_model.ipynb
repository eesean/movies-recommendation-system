{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7WmW2MsJq7U"
      },
      "source": [
        "# Imports & Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iaFz-aJJvWt"
      },
      "source": [
        "## Importing relavent packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owo3u8D8ym9J"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "from collections import Counter\n",
        "from itertools import chain\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import seaborn as sns\n",
        "import gdown\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD_UadzmyzWf"
      },
      "source": [
        "## Loading Preprocessed files into Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baDtH3KLy3Jm",
        "outputId": "c7fc683a-bdcd-44e0-efc0-2f6afc6801df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vUxq_77g3r1jH1S3Zctmj-u5pArq7iZd\n",
            "To: /content/movies_metadata.csv\n",
            "100%|██████████| 50.9M/50.9M [00:00<00:00, 54.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1lNJbFv82a2HTSaHqY7yloXoPovUpy6zn\n",
            "To: /content/ratings_small.csv\n",
            "100%|██████████| 1.46M/1.46M [00:00<00:00, 123MB/s]\n"
          ]
        }
      ],
      "source": [
        "#### MOVIES DATA #####\n",
        "metadata_drive = '1vUxq_77g3r1jH1S3Zctmj-u5pArq7iZd'\n",
        "gdown.download(f\"https://drive.google.com/uc?id={metadata_drive}\", \"movies_metadata.csv\", quiet=False)\n",
        "df_movies_metadata = pd.read_csv(\"movies_metadata.csv\")\n",
        "\n",
        "##### LOAD RATINGS DATA ####\n",
        "ratings_small_drive = '1lNJbFv82a2HTSaHqY7yloXoPovUpy6zn'\n",
        "gdown.download(f\"https://drive.google.com/uc?id={ratings_small_drive}\", \"ratings_small.csv\", quiet=False)\n",
        "df_ratings = pd.read_csv(\"ratings_small.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "id": "79E5sdla0I9C",
        "outputId": "99221ced-5e76-4bb8-fdcb-6bb91695ce97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   adult                      genres     id original_language  \\\n",
              "0  False   Animation, Comedy, Family    862                en   \n",
              "1  False  Adventure, Fantasy, Family   8844                en   \n",
              "2  False             Romance, Comedy  15602                en   \n",
              "3  False      Comedy, Drama, Romance  31357                en   \n",
              "4  False                      Comedy  11862                en   \n",
              "\n",
              "                original_title  \\\n",
              "0                    Toy Story   \n",
              "1                      Jumanji   \n",
              "2             Grumpier Old Men   \n",
              "3            Waiting to Exhale   \n",
              "4  Father of the Bride Part II   \n",
              "\n",
              "                                            overview  \\\n",
              "0  Led by Woody, Andy's toys live happily in his ...   \n",
              "1  When siblings Judy and Peter discover an encha...   \n",
              "2  A family wedding reignites the ancient feud be...   \n",
              "3  Cheated on, mistreated and stepped on, the wom...   \n",
              "4  Just when George Banks has recovered from his ...   \n",
              "\n",
              "                                production_companies  \\\n",
              "0                            Pixar Animation Studios   \n",
              "1  TriStar Pictures, Teitler Film, Interscope Com...   \n",
              "2                       Warner Bros., Lancaster Gate   \n",
              "3             Twentieth Century Fox Film Corporation   \n",
              "4         Sandollar Productions, Touchstone Pictures   \n",
              "\n",
              "       production_countries   spoken_languages  release_year runtime_category  \\\n",
              "0  United States of America            English          1995           Medium   \n",
              "1  United States of America  English, Français          1995           Medium   \n",
              "2  United States of America            English          1995           Medium   \n",
              "3  United States of America            English          1995             Long   \n",
              "4  United States of America            English          1995           Medium   \n",
              "\n",
              "   vote_count_log  vote_average_norm  vote_count_norm  popularity_norm  \\\n",
              "0        8.597113               0.77         0.900011         0.040087   \n",
              "1        7.789040               0.69         0.815416         0.031079   \n",
              "2        4.532599               0.65         0.474507         0.021394   \n",
              "3        3.555348               0.61         0.372201         0.007049   \n",
              "4        5.159055               0.57         0.540089         0.015320   \n",
              "\n",
              "   years_since_release                                     keyword_values  \\\n",
              "0                   22  jealousy, toy, boy, friendship, friends, rival...   \n",
              "1                   22  board game, disappearance, based on children's...   \n",
              "2                   22  fishing, best friend, duringcreditsstinger, ol...   \n",
              "3                   22  based on novel, interracial relationship, sing...   \n",
              "4                   22  baby, midlife crisis, confidence, aging, daugh...   \n",
              "\n",
              "                              textual_representation  \n",
              "0  This movie is titled Toy Story, produced in Un...  \n",
              "1  This movie is titled Jumanji, produced in Unit...  \n",
              "2  This movie is titled Grumpier Old Men, produce...  \n",
              "3  This movie is titled Waiting to Exhale, produc...  \n",
              "4  This movie is titled Father of the Bride Part ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-12098e8f-bd2f-4fff-9811-8d9fce48d7a0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>adult</th>\n",
              "      <th>genres</th>\n",
              "      <th>id</th>\n",
              "      <th>original_language</th>\n",
              "      <th>original_title</th>\n",
              "      <th>overview</th>\n",
              "      <th>production_companies</th>\n",
              "      <th>production_countries</th>\n",
              "      <th>spoken_languages</th>\n",
              "      <th>release_year</th>\n",
              "      <th>runtime_category</th>\n",
              "      <th>vote_count_log</th>\n",
              "      <th>vote_average_norm</th>\n",
              "      <th>vote_count_norm</th>\n",
              "      <th>popularity_norm</th>\n",
              "      <th>years_since_release</th>\n",
              "      <th>keyword_values</th>\n",
              "      <th>textual_representation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>Animation, Comedy, Family</td>\n",
              "      <td>862</td>\n",
              "      <td>en</td>\n",
              "      <td>Toy Story</td>\n",
              "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
              "      <td>Pixar Animation Studios</td>\n",
              "      <td>United States of America</td>\n",
              "      <td>English</td>\n",
              "      <td>1995</td>\n",
              "      <td>Medium</td>\n",
              "      <td>8.597113</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.900011</td>\n",
              "      <td>0.040087</td>\n",
              "      <td>22</td>\n",
              "      <td>jealousy, toy, boy, friendship, friends, rival...</td>\n",
              "      <td>This movie is titled Toy Story, produced in Un...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>Adventure, Fantasy, Family</td>\n",
              "      <td>8844</td>\n",
              "      <td>en</td>\n",
              "      <td>Jumanji</td>\n",
              "      <td>When siblings Judy and Peter discover an encha...</td>\n",
              "      <td>TriStar Pictures, Teitler Film, Interscope Com...</td>\n",
              "      <td>United States of America</td>\n",
              "      <td>English, Français</td>\n",
              "      <td>1995</td>\n",
              "      <td>Medium</td>\n",
              "      <td>7.789040</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.815416</td>\n",
              "      <td>0.031079</td>\n",
              "      <td>22</td>\n",
              "      <td>board game, disappearance, based on children's...</td>\n",
              "      <td>This movie is titled Jumanji, produced in Unit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "      <td>Romance, Comedy</td>\n",
              "      <td>15602</td>\n",
              "      <td>en</td>\n",
              "      <td>Grumpier Old Men</td>\n",
              "      <td>A family wedding reignites the ancient feud be...</td>\n",
              "      <td>Warner Bros., Lancaster Gate</td>\n",
              "      <td>United States of America</td>\n",
              "      <td>English</td>\n",
              "      <td>1995</td>\n",
              "      <td>Medium</td>\n",
              "      <td>4.532599</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.474507</td>\n",
              "      <td>0.021394</td>\n",
              "      <td>22</td>\n",
              "      <td>fishing, best friend, duringcreditsstinger, ol...</td>\n",
              "      <td>This movie is titled Grumpier Old Men, produce...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>Comedy, Drama, Romance</td>\n",
              "      <td>31357</td>\n",
              "      <td>en</td>\n",
              "      <td>Waiting to Exhale</td>\n",
              "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
              "      <td>Twentieth Century Fox Film Corporation</td>\n",
              "      <td>United States of America</td>\n",
              "      <td>English</td>\n",
              "      <td>1995</td>\n",
              "      <td>Long</td>\n",
              "      <td>3.555348</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.372201</td>\n",
              "      <td>0.007049</td>\n",
              "      <td>22</td>\n",
              "      <td>based on novel, interracial relationship, sing...</td>\n",
              "      <td>This movie is titled Waiting to Exhale, produc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>11862</td>\n",
              "      <td>en</td>\n",
              "      <td>Father of the Bride Part II</td>\n",
              "      <td>Just when George Banks has recovered from his ...</td>\n",
              "      <td>Sandollar Productions, Touchstone Pictures</td>\n",
              "      <td>United States of America</td>\n",
              "      <td>English</td>\n",
              "      <td>1995</td>\n",
              "      <td>Medium</td>\n",
              "      <td>5.159055</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.540089</td>\n",
              "      <td>0.015320</td>\n",
              "      <td>22</td>\n",
              "      <td>baby, midlife crisis, confidence, aging, daugh...</td>\n",
              "      <td>This movie is titled Father of the Bride Part ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12098e8f-bd2f-4fff-9811-8d9fce48d7a0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-12098e8f-bd2f-4fff-9811-8d9fce48d7a0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-12098e8f-bd2f-4fff-9811-8d9fce48d7a0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4308168c-4217-4d53-8b79-5dcd03c609fb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4308168c-4217-4d53-8b79-5dcd03c609fb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4308168c-4217-4d53-8b79-5dcd03c609fb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_movies_metadata",
              "summary": "{\n  \"name\": \"df_movies_metadata\",\n  \"rows\": 45119,\n  \"fields\": [\n    {\n      \"column\": \"adult\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"genres\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4058,\n        \"samples\": [\n          \"Romance, Action\",\n          \"Documentary, Action, Comedy, Drama\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 111558,\n        \"min\": 2,\n        \"max\": 469172,\n        \"num_unique_values\": 45089,\n        \"samples\": [\n          4435,\n          23030\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"original_language\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 89,\n        \"samples\": [\n          \"ka\",\n          \"fy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"original_title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 43039,\n        \"samples\": [\n          \"Magic in the Moonlight\",\n          \"I Saw What You Did\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"overview\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 44222,\n        \"samples\": [\n          \"Sotiris is a police investigator in Athens who lives by a strict moral code. An honest man, he carries himself as though held down by the weight of the world. Dora is a cleaning lady, struggling to get by any way she can. Dealt a rough hand in life, she has developed a rich layer of cynicism and mistrust that informs her every action. When a man Sotiris believes is innocent is arrested for a brutal crime, his attempt to uncover the truth results in a grave mistake. Finding himself on the other side of the law for the first time, he places his fate in Dora, the only witness to his malfeasance and the only person who can help him, for better or for worse.\",\n          \"Two troubled adolescents chronicle the events that ultimately lead up to a terrifying assault on their school.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"production_companies\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 22598,\n        \"samples\": [\n          \"Madhouse, Kitty Films, Tokuma Japan Communications Co. Ltd.\",\n          \"StudioCanal, Canal+, TPS Star, Sofica Manon, Easy Company, A Plus Image 2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"production_countries\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2383,\n        \"samples\": [\n          \"Brazil, France, Italy\",\n          \"Poland, Czech Republic, Slovakia\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"spoken_languages\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1838,\n        \"samples\": [\n          \"\\u0a2a\\u0a70\\u0a1c\\u0a3e\\u0a2c\\u0a40\",\n          \"English, T\\u00fcrk\\u00e7e, \\u0627\\u0644\\u0639\\u0631\\u0628\\u064a\\u0629\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"release_year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24,\n        \"min\": 1874,\n        \"max\": 2020,\n        \"num_unique_values\": 135,\n        \"samples\": [\n          2007,\n          1966\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"runtime_category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Medium\",\n          \"Long\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vote_count_log\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7228713279996561,\n        \"min\": 0.0,\n        \"max\": 9.552226498441476,\n        \"num_unique_values\": 1820,\n        \"samples\": [\n          8.68490859582083,\n          7.370860166536716\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vote_average_norm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19003049043484818,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 92,\n        \"samples\": [\n          0.38,\n          0.81\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vote_count_norm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18036332453811213,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1820,\n        \"samples\": [\n          0.9092025400819216,\n          0.7716379178968729\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"popularity_norm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01100159895536356,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 43526,\n        \"samples\": [\n          0.0008137032364479,\n          0.0024245285330281\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"years_since_release\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24,\n        \"min\": -3,\n        \"max\": 143,\n        \"num_unique_values\": 135,\n        \"samples\": [\n          10,\n          51\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keyword_values\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27641,\n        \"samples\": [\n          \"mother, bachelor, marriage, salesman, courtship, hostess\",\n          \"prison, prisoner, revenge, haunting, electric chair\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"textual_representation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 45088,\n        \"samples\": [\n          \"This movie is titled \\u0905\\u0936\\u094b\\u0915, produced in India with \\u0939\\u093f\\u0928\\u094d\\u0926\\u0940 as the main language. It falls under the genres of Drama, History and explores themes of buddhism, emperor, commander, reue, india, ancient world, historical drama. Overview: In India, about 260 BC in the Empire of Magadha, the Prince Asoka (Shah Rukh Khan) survives to many betrayals of his brothers, leaded by the evil Susima (Ajit Kumar), who wants to kill him to inherit the throne. His mothers orders Asoka to leave Magadha, and while traveling, he meets Princess Kaurwaki (Karriena Kapoor) and her brother, Prince Aryan (Sooraj Balaji) from Kalinga, who are undercover and protected by General Bheema (Rahul Dev). Asoka and Kaurwaki falls in love for each other, but the mother of Asoka calls him back to Magadha. When he returns, he does not find Kaurwaki, who was attacked by traitors of Kalinga. When Asoka's mother is killed by a man of Susima, Asoka becomes mad, kills all his evil brothers but Sugatra, who escapes to Kalinga. Asoka decides to conquer Kalinga, but in the end, he concludes that he has not built an empire, but conquered only corpses and destroyed everything, and he decides to spread love and the Buddhism.\",\n          \"This movie is titled Arabesque, produced in United States of America with English as the main language. It falls under the genres of Action, Adventure, Thriller and explores themes of spy, professor. Overview: Story of international intrigue involving a university professor, an Arab prime minister, a ruthless businessman, a beautiful spy, and hieroglyphics.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df_movies_metadata.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmBF5qwu4hHf"
      },
      "source": [
        "# LSTM Data Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1ZhdLXt4hHf"
      },
      "source": [
        "Defining functions to clean text and combine genre and keyword fields"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LF1RVkBt4hHf",
        "outputId": "8370af97-212c-4e3f-b83e-ff21850544aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Clean text and remove stopwords\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    text = re.sub(r\"[^\\w\\s]\", '', text)  # Remove punctuation\n",
        "    text = re.sub(r\"\\d+\", '', text)      # Remove digits\n",
        "    text = text.lower().strip()          # Lowercase and strip\n",
        "\n",
        "    # Remove stopwords\n",
        "    tokens = [word for word in text.split() if word not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "def build_doc(row):\n",
        "    # Clean and combine genres\n",
        "    genres = preprocess_text(row['genres'].replace('|', ' ')) if isinstance(row['genres'], str) else \"\"\n",
        "\n",
        "    # Clean and combine keyword values (list of phrases → space-separated string)\n",
        "    keywords = preprocess_text(row['keyword_values'].replace(',', ' ')) if isinstance(row['keyword_values'], str) else \"\"\n",
        "\n",
        "    # Combine all parts into one document\n",
        "    return f\"{genres} {keywords}\".strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T__0VwlOKqc1"
      },
      "source": [
        "Training a Word2Vec model on tokenized genre and keyword text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fes-Df8G4hHf",
        "outputId": "67eb14d9-b53c-406d-ab9a-310a1502d064"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim --upgrade ## If encounter error, restart kernel and run again\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "df_movies_metadata['doc'] = df_movies_metadata.apply(build_doc, axis=1)\n",
        "df_movies_metadata['doc'].head()\n",
        "\n",
        "tokenized_docs = [doc.split() for doc in df_movies_metadata['doc'].tolist()]\n",
        "\n",
        "\n",
        "w2v_model = Word2Vec(\n",
        "    sentences=tokenized_docs,\n",
        "    vector_size=100,\n",
        "    window=5,\n",
        "    min_count=1,\n",
        "    sg=1,  # Skip-gram\n",
        "    workers=4,\n",
        "    epochs=20\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjL-F1g34hHf"
      },
      "source": [
        "Generating average Word2Vec embeddings for each movie document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H24AggT84hHg"
      },
      "outputs": [],
      "source": [
        "def embed_doc(doc, w2v_model, embedding_dim=100):\n",
        "    tokens = doc.split()\n",
        "    vecs = [w2v_model.wv[token] for token in tokens if token in w2v_model.wv]\n",
        "    return np.mean(vecs, axis=0) if vecs else np.zeros(embedding_dim)\n",
        "\n",
        "# Apply to all rows\n",
        "embedding_dim = w2v_model.vector_size\n",
        "df_movies_metadata['embedding'] = df_movies_metadata['doc'].apply(lambda doc: embed_doc(doc, w2v_model, embedding_dim))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPaILw6GLIMF"
      },
      "source": [
        "For each movie, the code concatenates three types of features:\n",
        "- A semantic vector from the Word2Vec model, representing textual information (e.g., genres, keywords),\n",
        "- Three normalized numerical features: `vote_average_norm`, `vote_count_norm`, and `release_year_norm`,\n",
        "- Encoded IDs for categorical attributes like production company and runtime category (stored separately)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOuL4sGf4hHg"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "prod_encoder = LabelEncoder()\n",
        "runtime_encoder = LabelEncoder()\n",
        "\n",
        "df_movies_metadata['prod_id'] = prod_encoder.fit_transform(df_movies_metadata['production_companies'])\n",
        "df_movies_metadata['runtime_id'] = runtime_encoder.fit_transform(df_movies_metadata['runtime_category'])\n",
        "\n",
        "min_year = df_movies_metadata['release_year'].min()\n",
        "max_year = df_movies_metadata['release_year'].max()\n",
        "\n",
        "df_movies_metadata['release_year_norm'] = (df_movies_metadata['release_year'] - min_year) / (max_year - min_year)\n",
        "\n",
        "num_prods = df_movies_metadata['prod_id'].nunique()\n",
        "num_runtimes = df_movies_metadata['runtime_id'].nunique()\n",
        "\n",
        "\n",
        "combined_features = []\n",
        "prod_ids = []\n",
        "runtime_ids = []\n",
        "\n",
        "for i, row in df_movies_metadata.iterrows():\n",
        "    # Word2Vec embedding\n",
        "    vector = row['embedding']\n",
        "\n",
        "    # Normalized numeric features\n",
        "    numerics = row[['vote_average_norm', 'vote_count_norm', 'release_year_norm']].values\n",
        "\n",
        "    # Combine semantic and numeric features\n",
        "    full_vector = np.concatenate([vector, numerics])\n",
        "    combined_features.append(full_vector)\n",
        "\n",
        "    # Keep separate category IDs for embedding\n",
        "    prod_ids.append(row['prod_id'])\n",
        "    runtime_ids.append(row['runtime_id'])\n",
        "\n",
        "# Final matrix for LSTM input\n",
        "combined_vector = np.array(combined_features)  # shape: [num_samples, input_dim]\n",
        "prod_ids = np.array(prod_ids)                  # shape: [num_samples]\n",
        "runtime_ids = np.array(runtime_ids)            # shape: [num_samples]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b_DqnQC44hHg",
        "outputId": "a1eab4c6-bcc5-435c-f56e-ad2b1b37356d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   adult                            genres     id original_language  \\\n",
              "0  False         Animation, Comedy, Family    862                en   \n",
              "1  False        Adventure, Fantasy, Family   8844                en   \n",
              "2  False                   Romance, Comedy  15602                en   \n",
              "3  False            Comedy, Drama, Romance  31357                en   \n",
              "4  False                            Comedy  11862                en   \n",
              "5  False    Action, Crime, Drama, Thriller    949                en   \n",
              "6  False                   Comedy, Romance  11860                en   \n",
              "7  False  Action, Adventure, Drama, Family  45325                en   \n",
              "8  False       Action, Adventure, Thriller   9091                en   \n",
              "9  False       Adventure, Action, Thriller    710                en   \n",
              "\n",
              "                original_title  \\\n",
              "0                    Toy Story   \n",
              "1                      Jumanji   \n",
              "2             Grumpier Old Men   \n",
              "3            Waiting to Exhale   \n",
              "4  Father of the Bride Part II   \n",
              "5                         Heat   \n",
              "6                      Sabrina   \n",
              "7                 Tom and Huck   \n",
              "8                 Sudden Death   \n",
              "9                    GoldenEye   \n",
              "\n",
              "                                            overview  \\\n",
              "0  Led by Woody, Andy's toys live happily in his ...   \n",
              "1  When siblings Judy and Peter discover an encha...   \n",
              "2  A family wedding reignites the ancient feud be...   \n",
              "3  Cheated on, mistreated and stepped on, the wom...   \n",
              "4  Just when George Banks has recovered from his ...   \n",
              "5  Obsessive master thief, Neil McCauley leads a ...   \n",
              "6  An ugly duckling having undergone a remarkable...   \n",
              "7  A mischievous young boy, Tom Sawyer, witnesses...   \n",
              "8  International action superstar Jean Claude Van...   \n",
              "9  James Bond must unmask the mysterious head of ...   \n",
              "\n",
              "                                production_companies  \\\n",
              "0                            Pixar Animation Studios   \n",
              "1  TriStar Pictures, Teitler Film, Interscope Com...   \n",
              "2                       Warner Bros., Lancaster Gate   \n",
              "3             Twentieth Century Fox Film Corporation   \n",
              "4         Sandollar Productions, Touchstone Pictures   \n",
              "5    Regency Enterprises, Forward Pass, Warner Bros.   \n",
              "6  Paramount Pictures, Scott Rudin Productions, M...   \n",
              "7                               Walt Disney Pictures   \n",
              "8  Universal Pictures, Imperial Entertainment, Si...   \n",
              "9                    United Artists, Eon Productions   \n",
              "\n",
              "                       production_countries           spoken_languages  \\\n",
              "0                  United States of America                    English   \n",
              "1                  United States of America          English, Français   \n",
              "2                  United States of America                    English   \n",
              "3                  United States of America                    English   \n",
              "4                  United States of America                    English   \n",
              "5                  United States of America           English, Español   \n",
              "6         Germany, United States of America          Français, English   \n",
              "7                  United States of America           English, Deutsch   \n",
              "8                  United States of America                    English   \n",
              "9  United Kingdom, United States of America  English, Pусский, Español   \n",
              "\n",
              "   release_year  ... popularity_norm  years_since_release  \\\n",
              "0          1995  ...        0.040087                   22   \n",
              "1          1995  ...        0.031079                   22   \n",
              "2          1995  ...        0.021394                   22   \n",
              "3          1995  ...        0.007049                   22   \n",
              "4          1995  ...        0.015320                   22   \n",
              "5          1995  ...        0.032740                   22   \n",
              "6          1995  ...        0.012196                   22   \n",
              "7          1995  ...        0.004678                   22   \n",
              "8          1995  ...        0.009556                   22   \n",
              "9          1995  ...        0.026824                   22   \n",
              "\n",
              "                                      keyword_values  \\\n",
              "0  jealousy, toy, boy, friendship, friends, rival...   \n",
              "1  board game, disappearance, based on children's...   \n",
              "2  fishing, best friend, duringcreditsstinger, ol...   \n",
              "3  based on novel, interracial relationship, sing...   \n",
              "4  baby, midlife crisis, confidence, aging, daugh...   \n",
              "5  robbery, detective, bank, obsession, chase, sh...   \n",
              "6  paris, brother brother relationship, chauffeur...   \n",
              "7                Action,  Adventure,  Drama,  Family   \n",
              "8      terrorist, hostage, explosive, vice president   \n",
              "9  cuba, falsely accused, secret identity, comput...   \n",
              "\n",
              "                              textual_representation  \\\n",
              "0  This movie is titled Toy Story, produced in Un...   \n",
              "1  This movie is titled Jumanji, produced in Unit...   \n",
              "2  This movie is titled Grumpier Old Men, produce...   \n",
              "3  This movie is titled Waiting to Exhale, produc...   \n",
              "4  This movie is titled Father of the Bride Part ...   \n",
              "5  This movie is titled Heat, produced in United ...   \n",
              "6  This movie is titled Sabrina, produced in Germ...   \n",
              "7  This movie is titled Tom and Huck, produced in...   \n",
              "8  This movie is titled Sudden Death, produced in...   \n",
              "9  This movie is titled GoldenEye, produced in Un...   \n",
              "\n",
              "                                                 doc  \\\n",
              "0  animation comedy family jealousy toy boy frien...   \n",
              "1  adventure fantasy family board game disappeara...   \n",
              "2  romance comedy fishing best friend duringcredi...   \n",
              "3  comedy drama romance based novel interracial r...   \n",
              "4  comedy baby midlife crisis confidence aging da...   \n",
              "5  action crime drama thriller robbery detective ...   \n",
              "6  comedy romance paris brother brother relations...   \n",
              "7  action adventure drama family action adventure...   \n",
              "8  action adventure thriller terrorist hostage ex...   \n",
              "9  adventure action thriller cuba falsely accused...   \n",
              "\n",
              "                                           embedding prod_id runtime_id  \\\n",
              "0  [-0.11513898, 0.008001769, -0.019505141, -0.09...   15199          1   \n",
              "1  [-0.3166961, 0.2819797, -0.15894498, -0.022609...   19622          1   \n",
              "2  [-0.31996247, 0.27372667, -0.28294957, -0.0098...   21675          1   \n",
              "3  [-0.17462923, 0.01776824, -0.24283282, -0.0685...   19763          0   \n",
              "4  [0.13128638, 0.073717125, -0.13439795, -0.2470...   16838          1   \n",
              "5  [-0.35876963, -0.190521, -0.094962895, 0.09381...   16114          0   \n",
              "6  [-0.12749855, -0.0057888348, -0.14918678, 0.09...   14774          0   \n",
              "7  [-0.1416744, 0.23635162, -0.16573212, 0.128426...   21394          1   \n",
              "8  [-0.37880528, -0.06083382, 0.07977502, 0.20052...   20643          1   \n",
              "9  [-0.14259414, 0.07861366, 0.07763441, 0.018767...   20312          0   \n",
              "\n",
              "  release_year_norm                                    combined_vector  \n",
              "0          0.828767  [-0.11513897776603699, 0.008001768961548805, -...  \n",
              "1          0.828767  [-0.3166961073875427, 0.2819797098636627, -0.1...  \n",
              "2          0.828767  [-0.3199624717235565, 0.2737266719341278, -0.2...  \n",
              "3          0.828767  [-0.17462922632694244, 0.017768239602446556, -...  \n",
              "4          0.828767  [0.1312863826751709, 0.07371712476015091, -0.1...  \n",
              "5          0.828767  [-0.35876962542533875, -0.1905210018157959, -0...  \n",
              "6          0.828767  [-0.1274985522031784, -0.005788834765553474, -...  \n",
              "7          0.828767  [-0.14167439937591553, 0.2363516241312027, -0....  \n",
              "8          0.828767  [-0.3788052797317505, -0.06083381921052933, 0....  \n",
              "9          0.828767  [-0.1425941437482834, 0.07861366122961044, 0.0...  \n",
              "\n",
              "[10 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-16c01499-097e-4781-b065-1f73f1ae4287\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>adult</th>\n",
              "      <th>genres</th>\n",
              "      <th>id</th>\n",
              "      <th>original_language</th>\n",
              "      <th>original_title</th>\n",
              "      <th>overview</th>\n",
              "      <th>production_companies</th>\n",
              "      <th>production_countries</th>\n",
              "      <th>spoken_languages</th>\n",
              "      <th>release_year</th>\n",
              "      <th>...</th>\n",
              "      <th>popularity_norm</th>\n",
              "      <th>years_since_release</th>\n",
              "      <th>keyword_values</th>\n",
              "      <th>textual_representation</th>\n",
              "      <th>doc</th>\n",
              "      <th>embedding</th>\n",
              "      <th>prod_id</th>\n",
              "      <th>runtime_id</th>\n",
              "      <th>release_year_norm</th>\n",
              "      <th>combined_vector</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>Animation, Comedy, Family</td>\n",
              "      <td>862</td>\n",
              "      <td>en</td>\n",
              "      <td>Toy Story</td>\n",
              "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
              "      <td>Pixar Animation Studios</td>\n",
              "      <td>United States of America</td>\n",
              "      <td>English</td>\n",
              "      <td>1995</td>\n",
              "      <td>...</td>\n",
              "      <td>0.040087</td>\n",
              "      <td>22</td>\n",
              "      <td>jealousy, toy, boy, friendship, friends, rival...</td>\n",
              "      <td>This movie is titled Toy Story, produced in Un...</td>\n",
              "      <td>animation comedy family jealousy toy boy frien...</td>\n",
              "      <td>[-0.11513898, 0.008001769, -0.019505141, -0.09...</td>\n",
              "      <td>15199</td>\n",
              "      <td>1</td>\n",
              "      <td>0.828767</td>\n",
              "      <td>[-0.11513897776603699, 0.008001768961548805, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>Adventure, Fantasy, Family</td>\n",
              "      <td>8844</td>\n",
              "      <td>en</td>\n",
              "      <td>Jumanji</td>\n",
              "      <td>When siblings Judy and Peter discover an encha...</td>\n",
              "      <td>TriStar Pictures, Teitler Film, Interscope Com...</td>\n",
              "      <td>United States of America</td>\n",
              "      <td>English, Français</td>\n",
              "      <td>1995</td>\n",
              "      <td>...</td>\n",
              "      <td>0.031079</td>\n",
              "      <td>22</td>\n",
              "      <td>board game, disappearance, based on children's...</td>\n",
              "      <td>This movie is titled Jumanji, produced in Unit...</td>\n",
              "      <td>adventure fantasy family board game disappeara...</td>\n",
              "      <td>[-0.3166961, 0.2819797, -0.15894498, -0.022609...</td>\n",
              "      <td>19622</td>\n",
              "      <td>1</td>\n",
              "      <td>0.828767</td>\n",
              "      <td>[-0.3166961073875427, 0.2819797098636627, -0.1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "      <td>Romance, Comedy</td>\n",
              "      <td>15602</td>\n",
              "      <td>en</td>\n",
              "      <td>Grumpier Old Men</td>\n",
              "      <td>A family wedding reignites the ancient feud be...</td>\n",
              "      <td>Warner Bros., Lancaster Gate</td>\n",
              "      <td>United States of America</td>\n",
              "      <td>English</td>\n",
              "      <td>1995</td>\n",
              "      <td>...</td>\n",
              "      <td>0.021394</td>\n",
              "      <td>22</td>\n",
              "      <td>fishing, best friend, duringcreditsstinger, ol...</td>\n",
              "      <td>This movie is titled Grumpier Old Men, produce...</td>\n",
              "      <td>romance comedy fishing best friend duringcredi...</td>\n",
              "      <td>[-0.31996247, 0.27372667, -0.28294957, -0.0098...</td>\n",
              "      <td>21675</td>\n",
              "      <td>1</td>\n",
              "      <td>0.828767</td>\n",
              "      <td>[-0.3199624717235565, 0.2737266719341278, -0.2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>Comedy, Drama, Romance</td>\n",
              "      <td>31357</td>\n",
              "      <td>en</td>\n",
              "      <td>Waiting to Exhale</td>\n",
              "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
              "      <td>Twentieth Century Fox Film Corporation</td>\n",
              "      <td>United States of America</td>\n",
              "      <td>English</td>\n",
              "      <td>1995</td>\n",
              "      <td>...</td>\n",
              "      <td>0.007049</td>\n",
              "      <td>22</td>\n",
              "      <td>based on novel, interracial relationship, sing...</td>\n",
              "      <td>This movie is titled Waiting to Exhale, produc...</td>\n",
              "      <td>comedy drama romance based novel interracial r...</td>\n",
              "      <td>[-0.17462923, 0.01776824, -0.24283282, -0.0685...</td>\n",
              "      <td>19763</td>\n",
              "      <td>0</td>\n",
              "      <td>0.828767</td>\n",
              "      <td>[-0.17462922632694244, 0.017768239602446556, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>11862</td>\n",
              "      <td>en</td>\n",
              "      <td>Father of the Bride Part II</td>\n",
              "      <td>Just when George Banks has recovered from his ...</td>\n",
              "      <td>Sandollar Productions, Touchstone Pictures</td>\n",
              "      <td>United States of America</td>\n",
              "      <td>English</td>\n",
              "      <td>1995</td>\n",
              "      <td>...</td>\n",
              "      <td>0.015320</td>\n",
              "      <td>22</td>\n",
              "      <td>baby, midlife crisis, confidence, aging, daugh...</td>\n",
              "      <td>This movie is titled Father of the Bride Part ...</td>\n",
              "      <td>comedy baby midlife crisis confidence aging da...</td>\n",
              "      <td>[0.13128638, 0.073717125, -0.13439795, -0.2470...</td>\n",
              "      <td>16838</td>\n",
              "      <td>1</td>\n",
              "      <td>0.828767</td>\n",
              "      <td>[0.1312863826751709, 0.07371712476015091, -0.1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>False</td>\n",
              "      <td>Action, Crime, Drama, Thriller</td>\n",
              "      <td>949</td>\n",
              "      <td>en</td>\n",
              "      <td>Heat</td>\n",
              "      <td>Obsessive master thief, Neil McCauley leads a ...</td>\n",
              "      <td>Regency Enterprises, Forward Pass, Warner Bros.</td>\n",
              "      <td>United States of America</td>\n",
              "      <td>English, Español</td>\n",
              "      <td>1995</td>\n",
              "      <td>...</td>\n",
              "      <td>0.032740</td>\n",
              "      <td>22</td>\n",
              "      <td>robbery, detective, bank, obsession, chase, sh...</td>\n",
              "      <td>This movie is titled Heat, produced in United ...</td>\n",
              "      <td>action crime drama thriller robbery detective ...</td>\n",
              "      <td>[-0.35876963, -0.190521, -0.094962895, 0.09381...</td>\n",
              "      <td>16114</td>\n",
              "      <td>0</td>\n",
              "      <td>0.828767</td>\n",
              "      <td>[-0.35876962542533875, -0.1905210018157959, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>False</td>\n",
              "      <td>Comedy, Romance</td>\n",
              "      <td>11860</td>\n",
              "      <td>en</td>\n",
              "      <td>Sabrina</td>\n",
              "      <td>An ugly duckling having undergone a remarkable...</td>\n",
              "      <td>Paramount Pictures, Scott Rudin Productions, M...</td>\n",
              "      <td>Germany, United States of America</td>\n",
              "      <td>Français, English</td>\n",
              "      <td>1995</td>\n",
              "      <td>...</td>\n",
              "      <td>0.012196</td>\n",
              "      <td>22</td>\n",
              "      <td>paris, brother brother relationship, chauffeur...</td>\n",
              "      <td>This movie is titled Sabrina, produced in Germ...</td>\n",
              "      <td>comedy romance paris brother brother relations...</td>\n",
              "      <td>[-0.12749855, -0.0057888348, -0.14918678, 0.09...</td>\n",
              "      <td>14774</td>\n",
              "      <td>0</td>\n",
              "      <td>0.828767</td>\n",
              "      <td>[-0.1274985522031784, -0.005788834765553474, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>False</td>\n",
              "      <td>Action, Adventure, Drama, Family</td>\n",
              "      <td>45325</td>\n",
              "      <td>en</td>\n",
              "      <td>Tom and Huck</td>\n",
              "      <td>A mischievous young boy, Tom Sawyer, witnesses...</td>\n",
              "      <td>Walt Disney Pictures</td>\n",
              "      <td>United States of America</td>\n",
              "      <td>English, Deutsch</td>\n",
              "      <td>1995</td>\n",
              "      <td>...</td>\n",
              "      <td>0.004678</td>\n",
              "      <td>22</td>\n",
              "      <td>Action,  Adventure,  Drama,  Family</td>\n",
              "      <td>This movie is titled Tom and Huck, produced in...</td>\n",
              "      <td>action adventure drama family action adventure...</td>\n",
              "      <td>[-0.1416744, 0.23635162, -0.16573212, 0.128426...</td>\n",
              "      <td>21394</td>\n",
              "      <td>1</td>\n",
              "      <td>0.828767</td>\n",
              "      <td>[-0.14167439937591553, 0.2363516241312027, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>False</td>\n",
              "      <td>Action, Adventure, Thriller</td>\n",
              "      <td>9091</td>\n",
              "      <td>en</td>\n",
              "      <td>Sudden Death</td>\n",
              "      <td>International action superstar Jean Claude Van...</td>\n",
              "      <td>Universal Pictures, Imperial Entertainment, Si...</td>\n",
              "      <td>United States of America</td>\n",
              "      <td>English</td>\n",
              "      <td>1995</td>\n",
              "      <td>...</td>\n",
              "      <td>0.009556</td>\n",
              "      <td>22</td>\n",
              "      <td>terrorist, hostage, explosive, vice president</td>\n",
              "      <td>This movie is titled Sudden Death, produced in...</td>\n",
              "      <td>action adventure thriller terrorist hostage ex...</td>\n",
              "      <td>[-0.37880528, -0.06083382, 0.07977502, 0.20052...</td>\n",
              "      <td>20643</td>\n",
              "      <td>1</td>\n",
              "      <td>0.828767</td>\n",
              "      <td>[-0.3788052797317505, -0.06083381921052933, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>False</td>\n",
              "      <td>Adventure, Action, Thriller</td>\n",
              "      <td>710</td>\n",
              "      <td>en</td>\n",
              "      <td>GoldenEye</td>\n",
              "      <td>James Bond must unmask the mysterious head of ...</td>\n",
              "      <td>United Artists, Eon Productions</td>\n",
              "      <td>United Kingdom, United States of America</td>\n",
              "      <td>English, Pусский, Español</td>\n",
              "      <td>1995</td>\n",
              "      <td>...</td>\n",
              "      <td>0.026824</td>\n",
              "      <td>22</td>\n",
              "      <td>cuba, falsely accused, secret identity, comput...</td>\n",
              "      <td>This movie is titled GoldenEye, produced in Un...</td>\n",
              "      <td>adventure action thriller cuba falsely accused...</td>\n",
              "      <td>[-0.14259414, 0.07861366, 0.07763441, 0.018767...</td>\n",
              "      <td>20312</td>\n",
              "      <td>0</td>\n",
              "      <td>0.828767</td>\n",
              "      <td>[-0.1425941437482834, 0.07861366122961044, 0.0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 24 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16c01499-097e-4781-b065-1f73f1ae4287')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-16c01499-097e-4781-b065-1f73f1ae4287 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-16c01499-097e-4781-b065-1f73f1ae4287');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-960b2ae0-5fa1-46fa-a4e6-9ab4625fc359\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-960b2ae0-5fa1-46fa-a4e6-9ab4625fc359')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-960b2ae0-5fa1-46fa-a4e6-9ab4625fc359 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_movies_metadata"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df_movies_metadata['combined_vector'] = combined_features\n",
        "combined_vector = np.stack(df_movies_metadata['combined_vector'].values)\n",
        "df_movies_metadata.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_hCDEE_uc7q"
      },
      "source": [
        "Merging Movie Metadata with Ratings to Form User Interaction History\n",
        "\n",
        "After the merge, the resulting DataFrame (`df_small_ratings`) is sorted by `userId` and `date_time` to maintain a chronological order of user activity. This ordering is crucial for models like LSTM, which rely on the temporal sequence of user interactions to learn behavioral patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "nnZq5ekBucLA",
        "outputId": "80481b8e-9fe0-4ae2-ce64-efb3dcdacde3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   userId  movieId  rating            date_time  \\\n",
              "4       1     2294     2.0  2009-12-14 02:51:48   \n",
              "5       1     2455     2.5  2009-12-14 02:51:53   \n",
              "0       1     1371     2.5  2009-12-14 02:52:15   \n",
              "2       1     2105     4.0  2009-12-14 02:52:19   \n",
              "3       1     2193     2.0  2009-12-14 02:53:18   \n",
              "\n",
              "                   original_title  prod_id  runtime_id  \\\n",
              "4  Jay and Silent Bob Strike Back     5488           1   \n",
              "5              Vivement dimanche!    10955           1   \n",
              "0                       Rocky III    20264           1   \n",
              "2                    American Pie    20810           1   \n",
              "3                        My Tutor     4904           1   \n",
              "\n",
              "                                     combined_vector  \n",
              "4  [-0.2089790254831314, 0.1709032654762268, -0.2...  \n",
              "5  [-0.11371078342199326, -0.0551886148750782, 0....  \n",
              "0  [-0.5076473951339722, -0.06163134425878525, 0....  \n",
              "2  [-0.41693365573883057, 0.29266980290412903, -0...  \n",
              "3  [-0.20992015302181244, 0.2695636451244354, -0....  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d3c1c2e3-92d1-4ec4-b7e2-ad3859661e97\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>date_time</th>\n",
              "      <th>original_title</th>\n",
              "      <th>prod_id</th>\n",
              "      <th>runtime_id</th>\n",
              "      <th>combined_vector</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2294</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2009-12-14 02:51:48</td>\n",
              "      <td>Jay and Silent Bob Strike Back</td>\n",
              "      <td>5488</td>\n",
              "      <td>1</td>\n",
              "      <td>[-0.2089790254831314, 0.1709032654762268, -0.2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>2455</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2009-12-14 02:51:53</td>\n",
              "      <td>Vivement dimanche!</td>\n",
              "      <td>10955</td>\n",
              "      <td>1</td>\n",
              "      <td>[-0.11371078342199326, -0.0551886148750782, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1371</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2009-12-14 02:52:15</td>\n",
              "      <td>Rocky III</td>\n",
              "      <td>20264</td>\n",
              "      <td>1</td>\n",
              "      <td>[-0.5076473951339722, -0.06163134425878525, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2105</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2009-12-14 02:52:19</td>\n",
              "      <td>American Pie</td>\n",
              "      <td>20810</td>\n",
              "      <td>1</td>\n",
              "      <td>[-0.41693365573883057, 0.29266980290412903, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2193</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2009-12-14 02:53:18</td>\n",
              "      <td>My Tutor</td>\n",
              "      <td>4904</td>\n",
              "      <td>1</td>\n",
              "      <td>[-0.20992015302181244, 0.2695636451244354, -0....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d3c1c2e3-92d1-4ec4-b7e2-ad3859661e97')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d3c1c2e3-92d1-4ec4-b7e2-ad3859661e97 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d3c1c2e3-92d1-4ec4-b7e2-ad3859661e97');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1bf50f11-cbc9-4f72-804b-267998c61b5f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1bf50f11-cbc9-4f72-804b-267998c61b5f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1bf50f11-cbc9-4f72-804b-267998c61b5f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_small_ratings",
              "summary": "{\n  \"name\": \"df_small_ratings\",\n  \"rows\": 44961,\n  \"fields\": [\n    {\n      \"column\": \"userId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 194,\n        \"min\": 1,\n        \"max\": 671,\n        \"num_unique_values\": 671,\n        \"samples\": [\n          362,\n          159,\n          481\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"movieId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15894,\n        \"min\": 2,\n        \"max\": 160718,\n        \"num_unique_values\": 2826,\n        \"samples\": [\n          3051,\n          2924,\n          43899\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.053289198860296,\n        \"min\": 0.5,\n        \"max\": 5.0,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1.5,\n          2.5,\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date_time\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 36047,\n        \"samples\": [\n          \"1999-10-12 01:32:53\",\n          \"2006-08-31 00:14:19\",\n          \"2005-05-02 01:31:53\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"original_title\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2794,\n        \"samples\": [\n          \"10 Things I Hate About You\",\n          \"DragonHeart\",\n          \"Carry On Screaming\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prod_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6732,\n        \"min\": 28,\n        \"max\": 22598,\n        \"num_unique_values\": 2066,\n        \"samples\": [\n          896,\n          7305,\n          17923\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"runtime_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1,\n          0,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"combined_vector\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# First, align the column names\n",
        "df_movies_and_keywords = df_movies_metadata.rename(columns={'id': 'movieId'})\n",
        "\n",
        "# Then perform the merge\n",
        "df_small_ratings = df_ratings.merge(\n",
        "    df_movies_and_keywords[['movieId','original_title', 'prod_id', 'runtime_id', 'combined_vector']],\n",
        "    on='movieId',\n",
        "    how='inner'  # or 'left' if you want to keep all ratings\n",
        ")\n",
        "\n",
        "df_small_ratings = df_small_ratings.sort_values(by=['userId', 'date_time'])\n",
        "\n",
        "\n",
        "df_small_ratings.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPmOeZA6jpCQ"
      },
      "source": [
        "Preparing Movie Embedding Matrix for Similarity Computation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfbxFwmNgPpO"
      },
      "outputs": [],
      "source": [
        "# Ensure every vector is converted to float32 numpy array\n",
        "movie_id_to_vector = {\n",
        "    row['movieId']: np.array(row['combined_vector'], dtype=np.float32)\n",
        "    for _, row in df_movies_and_keywords.iterrows()\n",
        "}\n",
        "\n",
        "# Sort movie IDs (for consistent indexing)\n",
        "movie_id_list = sorted(movie_id_to_vector.keys())\n",
        "\n",
        "# Stack all vectors into one 2D float32 array\n",
        "movie_db_vectors = np.stack([movie_id_to_vector[mid] for mid in movie_id_list])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_rAzJQum1XB"
      },
      "source": [
        "# LSTM with Softmax Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsvzrWdYm4Je"
      },
      "source": [
        "## Preparing Train-Test Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ipXHm2UFcn8"
      },
      "source": [
        "### Preparing Input for LSTM Softmax Classification\n",
        "\n",
        "To prepare inputs for the LSTM softmax classification model, we start by defining a fixed `max_len` that determines how many previous movie interactions are used as a sequence input. Each user's interaction history is sorted and processed using a sliding window approach, where each windowed segment of past interactions becomes one input sequence, and the next movie becomes the prediction target.\n",
        "\n",
        "To ensure sufficient sequence length, only users with at least `max_interactions` are selected. We construct a mapping (`movie_id_to_idx`) that indexes each unique movie, and prepare the full movie embedding matrix (`movie_db_vectors`) for downstream lookup and comparison.\n",
        "\n",
        "Users are then randomly split into training + validation(80%), and test sets (20%) using `train_test_split`. The training and validation users are used to generate multiple (input, target) pairs for supervised learning, while for the test set, only one held-out prediction per user is kept for fair evaluation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwDLobs0LVrJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "max_len = 5  # number of historical time steps\n",
        "max_interactions = 19\n",
        "\n",
        "movie_id_list = sorted(df_movies_and_keywords['movieId'].drop_duplicates())\n",
        "movie_id_to_idx = {movie_id: idx for idx, movie_id in enumerate(movie_id_list)}\n",
        "movie_db_vectors = np.vstack(df_movies_and_keywords.drop_duplicates('movieId').sort_values('movieId')['combined_vector'].tolist())\n",
        "\n",
        "# === Group by user and filter ===\n",
        "grouped = df_small_ratings.groupby('userId')\n",
        "filtered_users = [uid for uid, group in grouped if len(group) >= max_interactions]\n",
        "train_val_users, test_users = train_test_split(filtered_users, test_size=0.2, random_state=42)\n",
        "train_users, val_users = train_test_split(train_val_users, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0esEL2WlkPfX"
      },
      "source": [
        "Using a split ratio of 80-20, each user's sequence is divided into training and validation segments. For each point in the sequence, the model takes a padded sequence of up to `max_len` previous movies as input, and the next movie in the timeline as the prediction target. This way, multiple training samples can be generated from a single user.\n",
        "\n",
        "Each training and validation sample includes not just the sequence of movie embeddings but also the corresponding categorical metadata (`prod_id`, `runtime_id`), which are stored separately for embedding purposes.\n",
        "\n",
        "For test users, exactly one final sequence is created after the training/validation split point to simulate a real-world setting where the model must predict the next movie a user might watch. This ensures no information from the test interaction leaks into training and preserves the independence of evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhQmW5BbmvMk"
      },
      "outputs": [],
      "source": [
        "# Initialize empty lists to store training, validation, and test data\n",
        "prod_train, runtime_train = [], []\n",
        "prod_val, runtime_val = [], []\n",
        "prod_test, runtime_test = [], []\n",
        "X_train, y_train = [], []\n",
        "X_val, y_val = [], []\n",
        "X_test, y_test = [], []\n",
        "\n",
        "# Loop through each user in the filtered user set\n",
        "for uid in filtered_users:\n",
        "    # Retrieve and sort the user's interaction history by timestamp\n",
        "    group = grouped.get_group(uid).sort_values('date_time')\n",
        "    group = group.iloc[:max_interactions]  # Limit to max number of interactions\n",
        "\n",
        "    # Extract sequences of movie features and metadata\n",
        "    seq = group['combined_vector'].tolist()\n",
        "    movie_ids = group['movieId'].tolist()\n",
        "    prod_ids_seq = group['prod_id'].tolist()\n",
        "    runtime_ids_seq = group['runtime_id'].tolist()\n",
        "\n",
        "    # Define the split point for training/validation (80%)\n",
        "    split_point = int(0.8 * len(seq))\n",
        "\n",
        "    # Build training/validation samples using a sliding window\n",
        "    for i in range(1, split_point):\n",
        "        start = max(0, i - max_len)  # Look back up to max_len steps\n",
        "        x_seq = seq[start:i]\n",
        "        x_padded = [np.zeros_like(seq[0])] * (max_len - len(x_seq)) + x_seq  # Left-pad sequence\n",
        "\n",
        "        # Identify the next movie in the sequence as the target\n",
        "        target_movie_id = movie_ids[i]\n",
        "        target_idx = movie_id_to_idx[target_movie_id]\n",
        "\n",
        "        # Retrieve categorical metadata IDs\n",
        "        prod_id = prod_ids_seq[i]\n",
        "        runtime_id = runtime_ids_seq[i]\n",
        "\n",
        "        # Assign data to train or validation set based on user\n",
        "        if uid in train_users:\n",
        "            X_train.append(np.array(x_padded))\n",
        "            y_train.append(target_idx)\n",
        "            prod_train.append(prod_id)\n",
        "            runtime_train.append(runtime_id)\n",
        "        elif uid in val_users:\n",
        "            X_val.append(np.array(x_padded))\n",
        "            y_val.append(target_idx)\n",
        "            prod_val.append(prod_id)\n",
        "            runtime_val.append(runtime_id)\n",
        "\n",
        "    # Add one test sample for each user from the remaining sequence\n",
        "    if split_point < len(seq) and uid in test_users:\n",
        "        start = max(0, split_point - max_len)\n",
        "        x_seq = seq[start:split_point]\n",
        "        x_padded = [np.zeros_like(seq[0])] * (max_len - len(x_seq)) + x_seq\n",
        "\n",
        "        target_movie_id = movie_ids[split_point]\n",
        "        target_idx = movie_id_to_idx[target_movie_id]\n",
        "\n",
        "        prod_id = prod_ids_seq[split_point]\n",
        "        runtime_id = runtime_ids_seq[split_point]\n",
        "\n",
        "        X_test.append(np.array(x_padded))\n",
        "        y_test.append(target_idx)\n",
        "        prod_test.append(prod_id)\n",
        "        runtime_test.append(runtime_id)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWeSU2-pkkGV"
      },
      "source": [
        "DataLoader Preparation for LSTM Softmax Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oa8Bc2oLm8dB",
        "outputId": "84fca0d7-3e71-4774-f4fc-4934b511efc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Per-user temporal split completed with filtering and capping!\n",
            "X_train shape: torch.Size([4592, 5, 103])\n",
            "X_val shape: torch.Size([1148, 5, 103])\n",
            "X_test shape: torch.Size([103, 5, 103])\n",
            "Number of extra features per sample: prod_id, runtime_id\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "# === Convert sequence inputs to float32 arrays ===\n",
        "X_train = np.stack([np.array(x, dtype=np.float32) for x in X_train])\n",
        "X_val = np.stack([np.array(x, dtype=np.float32) for x in X_val])\n",
        "X_test = np.stack([np.array(x, dtype=np.float32) for x in X_test])\n",
        "\n",
        "# === Convert main labels to tensors ===\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "\n",
        "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
        "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
        "\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# === Convert categorical IDs to tensors (prod_id, runtime_id only) ===\n",
        "prod_train_tensor = torch.tensor(prod_train, dtype=torch.long)\n",
        "runtime_train_tensor = torch.tensor(runtime_train, dtype=torch.long)\n",
        "\n",
        "prod_val_tensor = torch.tensor(prod_val, dtype=torch.long)\n",
        "runtime_val_tensor = torch.tensor(runtime_val, dtype=torch.long)\n",
        "\n",
        "prod_test_tensor = torch.tensor(prod_test, dtype=torch.long)\n",
        "runtime_test_tensor = torch.tensor(runtime_test, dtype=torch.long)\n",
        "\n",
        "# === Create TensorDatasets (3 inputs: X, prod_id, runtime_id) ===\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor,\n",
        "                              prod_train_tensor, runtime_train_tensor)\n",
        "\n",
        "val_dataset = TensorDataset(X_val_tensor, y_val_tensor,\n",
        "                            prod_val_tensor, runtime_val_tensor)\n",
        "\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor,\n",
        "                             prod_test_tensor, runtime_test_tensor)\n",
        "\n",
        "# === DataLoaders ===\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# === Print summary ===\n",
        "print(\"Per-user temporal split completed with filtering and capping!\")\n",
        "print(\"X_train shape:\", X_train_tensor.shape)\n",
        "print(\"X_val shape:\", X_val_tensor.shape)\n",
        "print(\"X_test shape:\", X_test_tensor.shape)\n",
        "print(\"Number of extra features per sample: prod_id, runtime_id\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHXbkA27k1U1"
      },
      "source": [
        "### Defining Evaluation Metrics Functions\n",
        "In this recommendation setup, our goal is not to predict the exact next movie a user will watch, but rather to recommend **relevant** ones.\n",
        "\n",
        "We modify standard metrics (Precision@K, Recall@K, F1, NDCG) to use **cosine similarity** instead of exact ID matching. This allows us to reward predictions that are semantically close to the ground truth movie—even if the IDs differ—making our evaluation more flexible and aligned with real-world recommendation goals."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ut4jVb6fm-Zx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def precision_at_k_cosine(y_true, y_probs, movie_db_vectors, k=10, threshold=0.8):\n",
        "    total_hits = 0\n",
        "\n",
        "    for i in range(len(y_true)):\n",
        "        true_vec = movie_db_vectors[y_true[i]]\n",
        "        top_k = y_probs[i].argsort()[-k:][::-1]\n",
        "\n",
        "        hits = 0\n",
        "        for pred_idx in top_k:\n",
        "            pred_vec = movie_db_vectors[pred_idx]\n",
        "            cos_sim = cosine_similarity([true_vec], [pred_vec])[0][0]\n",
        "            if cos_sim >= threshold:\n",
        "                hits += 1\n",
        "\n",
        "        total_hits += hits / k  # per-sample precision\n",
        "\n",
        "    return total_hits / len(y_true)\n",
        "\n",
        "\n",
        "def recall_at_k_cosine(y_true, y_probs, movie_db_vectors, k=10, threshold=0.8):\n",
        "    hits = 0\n",
        "\n",
        "    for i in range(len(y_true)):\n",
        "        true_vec = movie_db_vectors[y_true[i]]\n",
        "        top_k = y_probs[i].argsort()[-k:][::-1]\n",
        "\n",
        "        for pred_idx in top_k:\n",
        "            pred_vec = movie_db_vectors[pred_idx]\n",
        "            cos_sim = cosine_similarity([true_vec], [pred_vec])[0][0]\n",
        "            if cos_sim >= threshold:\n",
        "                hits += 1\n",
        "                break  # one hit is enough\n",
        "    return hits / len(y_true)\n",
        "\n",
        "\n",
        "def f1_at_k(precision, recall):\n",
        "    if precision + recall == 0:\n",
        "        return 0.0\n",
        "    return 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "def dcg_at_k(ranked_list, true_label, k=10):\n",
        "    for i in range(min(k, len(ranked_list))):\n",
        "        if ranked_list[i] == true_label:\n",
        "            return 1 / np.log2(i + 2)  # +2 because i starts at 0\n",
        "    return 0.0\n",
        "\n",
        "def ndcg_cosine_at_k(y_true, y_probs, movie_db_vectors, k=10, threshold=0.8):\n",
        "    total_ndcg = 0.0\n",
        "    for i in range(len(y_true)):\n",
        "        true_vec = movie_db_vectors[y_true[i]]\n",
        "\n",
        "        # Get top-K predictions\n",
        "        top_k_indices = y_probs[i].argsort()[-k:][::-1]\n",
        "\n",
        "        # Relevance vector (1 if cosine ≥ threshold)\n",
        "        relevance_scores = []\n",
        "        for pred_idx in top_k_indices:\n",
        "            pred_vec = movie_db_vectors[pred_idx]\n",
        "            sim = cosine_similarity([true_vec], [pred_vec])[0][0]\n",
        "            relevance = 1 if sim >= threshold else 0\n",
        "            relevance_scores.append(relevance)\n",
        "\n",
        "        # --- DCG ---\n",
        "        dcg = 0.0\n",
        "        for rank, rel in enumerate(relevance_scores):\n",
        "            if rel:\n",
        "                dcg += 1 / np.log2(rank + 2)\n",
        "\n",
        "        # --- IDCG (ideal ranking) ---\n",
        "        ideal_rels = sorted(relevance_scores, reverse=True)\n",
        "        idcg = 0.0\n",
        "        for rank, rel in enumerate(ideal_rels):\n",
        "            if rel:\n",
        "                idcg += 1 / np.log2(rank + 2)\n",
        "\n",
        "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
        "        total_ndcg += ndcg\n",
        "\n",
        "    return total_ndcg / len(y_true)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9xEAwY_k-jk"
      },
      "source": [
        "## LSTM Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgYAKZPqlaxz"
      },
      "source": [
        "### LSTM Model Architecture for Movie Classification\n",
        "\n",
        "This model combines sequential movie watch history with categorical metadata to classify the next movie a user is likely to watch.\n",
        "\n",
        "The model architecture consists of the following components:\n",
        "\n",
        "- **LSTM Layer:** Processes sequences of movie feature vectors representing user history. The final hidden state summarizes temporal patterns of watched movies.\n",
        "- **Categorical Embeddings:** Production company and runtime category are embedded into lower-dimensional vectors using trainable `nn.Embedding` layers. These embeddings provide auxiliary context to the model.\n",
        "- **Feature Fusion:** The final LSTM output is concatenated with the categorical embeddings to form a single feature vector for each user.\n",
        "- **Feedforward Layers:** This fused representation passes through two linear layers with ReLU activation and dropout for regularization. The final output layer maps the hidden representation to a probability distribution over all movie classes.\n",
        "- **Output:** A softmax-compatible output layer predicts the most likely next movie from the list of known movies in the training set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0c7pqlKlIEn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MovieClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, num_movies, num_prods, num_runtimes,\n",
        "                 emb_dim=16, hidden_dim=64, dropout_rate=0.5):\n",
        "        super(MovieClassifier, self).__init__()\n",
        "\n",
        "        # LSTM for processing sequence of combined features\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # Embedding layers for categorical features\n",
        "        self.prod_emb = nn.Embedding(num_prods, emb_dim)\n",
        "        self.runtime_emb = nn.Embedding(num_runtimes, emb_dim)\n",
        "\n",
        "        # Concatenated input = LSTM output + prod_emb + runtime_emb\n",
        "        concat_input_dim = hidden_dim + 2 * emb_dim\n",
        "\n",
        "        # Feedforward layers\n",
        "        self.dropout1 = nn.Dropout(dropout_rate)\n",
        "        self.dense1 = nn.Linear(concat_input_dim, 128)\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "        self.concat_dense = nn.Linear(128, 128)\n",
        "\n",
        "        # Output layer\n",
        "        self.output_layer = nn.Linear(128, num_movies)\n",
        "\n",
        "    def forward(self, x, prod_ids, runtime_ids):\n",
        "        # x: [batch_size, seq_len, input_dim]\n",
        "        batch_size = x.size(0)\n",
        "        h0 = torch.zeros(1, batch_size, self.lstm.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(1, batch_size, self.lstm.hidden_size).to(x.device)\n",
        "\n",
        "        lstm_out, _ = self.lstm(x, (h0, c0))\n",
        "        x_seq = lstm_out[:, -1, :]  # take final time step output\n",
        "\n",
        "        # Embeddings\n",
        "        prod_vec = self.prod_emb(prod_ids)\n",
        "        runtime_vec = self.runtime_emb(runtime_ids)\n",
        "\n",
        "        # Combine LSTM output with embeddings\n",
        "        combined = torch.cat([x_seq, prod_vec, runtime_vec], dim=1)\n",
        "\n",
        "        # Feedforward\n",
        "        combined = self.dropout1(combined)\n",
        "        combined = F.relu(self.dense1(combined))\n",
        "        combined = self.dropout2(combined)\n",
        "        combined = F.relu(self.concat_dense(combined))\n",
        "\n",
        "        return self.output_layer(combined)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Apj8amyzlNls"
      },
      "source": [
        "Training and validation process for the LSTM-based movie recommendation model with a softmax classification head. During each epoch, the model learns to predict the next movie from a user's watch sequence using categorical features such as production company and runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gw3A4GG8nFS7"
      },
      "outputs": [],
      "source": [
        "def train_lstm_model(model, train_loader, val_loader, device, num_classes, epochs, lr):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss, correct, total = 0, 0, 0\n",
        "\n",
        "        for x_batch, y_batch, prod_batch, runtime_batch in train_loader:\n",
        "            x_batch = x_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            prod_batch = prod_batch.to(device)\n",
        "            runtime_batch = runtime_batch.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(x_batch, prod_batch, runtime_batch)\n",
        "\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            correct += (preds == y_batch).sum().item()\n",
        "            total += y_batch.size(0)\n",
        "\n",
        "        acc = correct / total\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {total_loss:.4f} - Accuracy: {acc:.4f}\")\n",
        "\n",
        "        # === Validation ===\n",
        "        model.eval()\n",
        "        val_loss, val_correct, val_total = 0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for x_val, y_val, prod_val, runtime_val in val_loader:\n",
        "                x_val = x_val.to(device)\n",
        "                y_val = y_val.to(device)\n",
        "                prod_val = prod_val.to(device)\n",
        "                runtime_val = runtime_val.to(device)\n",
        "\n",
        "                outputs = model(x_val, prod_val, runtime_val)\n",
        "                loss = criterion(outputs, y_val)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                preds = outputs.argmax(dim=1)\n",
        "                val_correct += (preds == y_val).sum().item()\n",
        "                val_total += y_val.size(0)\n",
        "\n",
        "        val_acc = val_correct / val_total\n",
        "        print(f\"Validation Loss = {val_loss:.4f} | Val Acc = {val_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9p9VZ7famjNR"
      },
      "source": [
        "### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k51SCR4FnKr7",
        "outputId": "1b44443e-1d29-4b0a-8752-9561629d75c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20 - Loss: 605.4605 - Accuracy: 0.0348\n",
            "Validation Loss = 122.6591 | Val Acc = 0.1359\n",
            "Epoch 2/20 - Loss: 426.3916 - Accuracy: 0.1032\n",
            "Validation Loss = 107.8969 | Val Acc = 0.2160\n",
            "Epoch 3/20 - Loss: 367.2227 - Accuracy: 0.1827\n",
            "Validation Loss = 94.3835 | Val Acc = 0.3145\n",
            "Epoch 4/20 - Loss: 316.9558 - Accuracy: 0.2493\n",
            "Validation Loss = 82.5455 | Val Acc = 0.4329\n",
            "Epoch 5/20 - Loss: 277.8885 - Accuracy: 0.3095\n",
            "Validation Loss = 74.5351 | Val Acc = 0.5401\n",
            "Epoch 6/20 - Loss: 246.2767 - Accuracy: 0.3491\n",
            "Validation Loss = 69.6137 | Val Acc = 0.6106\n",
            "Epoch 7/20 - Loss: 221.2745 - Accuracy: 0.3874\n",
            "Validation Loss = 65.9933 | Val Acc = 0.6890\n",
            "Epoch 8/20 - Loss: 198.7829 - Accuracy: 0.4307\n",
            "Validation Loss = 64.3018 | Val Acc = 0.7108\n",
            "Epoch 9/20 - Loss: 188.1177 - Accuracy: 0.4475\n",
            "Validation Loss = 62.5756 | Val Acc = 0.7274\n",
            "Epoch 10/20 - Loss: 176.1982 - Accuracy: 0.4732\n",
            "Validation Loss = 60.8072 | Val Acc = 0.7535\n",
            "Epoch 11/20 - Loss: 169.2770 - Accuracy: 0.4885\n",
            "Validation Loss = 60.1590 | Val Acc = 0.7544\n",
            "Epoch 12/20 - Loss: 158.7638 - Accuracy: 0.5039\n",
            "Validation Loss = 59.6947 | Val Acc = 0.7796\n",
            "Epoch 13/20 - Loss: 155.6074 - Accuracy: 0.5039\n",
            "Validation Loss = 59.7408 | Val Acc = 0.7840\n",
            "Epoch 14/20 - Loss: 153.5017 - Accuracy: 0.5144\n",
            "Validation Loss = 57.7922 | Val Acc = 0.7927\n",
            "Epoch 15/20 - Loss: 146.3110 - Accuracy: 0.5346\n",
            "Validation Loss = 58.4700 | Val Acc = 0.7988\n",
            "Epoch 16/20 - Loss: 142.3751 - Accuracy: 0.5285\n",
            "Validation Loss = 58.3292 | Val Acc = 0.8023\n",
            "Epoch 17/20 - Loss: 137.6640 - Accuracy: 0.5490\n",
            "Validation Loss = 57.3219 | Val Acc = 0.7988\n",
            "Epoch 18/20 - Loss: 135.9797 - Accuracy: 0.5475\n",
            "Validation Loss = 57.6668 | Val Acc = 0.8101\n",
            "Epoch 19/20 - Loss: 137.2667 - Accuracy: 0.5429\n",
            "Validation Loss = 57.9879 | Val Acc = 0.8014\n",
            "Epoch 20/20 - Loss: 130.6705 - Accuracy: 0.5564\n",
            "Validation Loss = 55.9196 | Val Acc = 0.8057\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define dimensions based on your data\n",
        "input_dim = combined_vector.shape[1]  # input feature size per timestep\n",
        "num_classes = movie_db_vectors.shape[0]  # total number of movie classes\n",
        "\n",
        "model = MovieClassifier(\n",
        "    input_dim=input_dim,\n",
        "    num_movies=num_classes,\n",
        "    num_prods=num_prods,\n",
        "    num_runtimes=num_runtimes,\n",
        ")\n",
        "\n",
        "train_lstm_model(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    device=device,\n",
        "    num_classes=num_classes,\n",
        "    epochs=20,        # or any number you want\n",
        "    lr=0.001           # learning rate\n",
        ")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2Zir6ANmc4l"
      },
      "source": [
        "### Evaluation\n",
        "\n",
        "For the softmax-based LSTM classification model, we evaluate its ability to predict the next movie a user is likely to watch from a predefined set of movie labels seen during training. The model is trained to output a probability distribution over all known movie classes using a softmax layer, and the prediction corresponds to the class with the highest probability.\n",
        "\n",
        "While classification accuracy serves as a direct measure of how often the model correctly identifies the next movie, this metric alone may not fully capture the quality of recommendations, especially in cases where semantically similar alternatives exist. To address this, we complement accuracy with ranking-based metrics using cosine similarity between the predicted softmax probabilities and movie embeddings.\n",
        "\n",
        "In this extended evaluation, we calculate Precision@K, Recall@K, F1@K, and NDCG@K. These metrics help assess whether the model ranks relevant or similar movies highly within the top-K predictions, based on cosine similarity to the ground truth movie vector. This is particularly useful in recommendation settings, where offering suitable or thematically related content is often more important than identifying a single correct label.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEpMCNTRmdm2"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def evaluate_model(model, test_loader, device, movie_db_vectors, k=10, threshold=0.8):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    all_probs = []\n",
        "    all_true = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_test, y_test, prod_test, runtime_test in test_loader:\n",
        "            x_test = x_test.to(device)\n",
        "            y_test = y_test.to(device)\n",
        "            prod_test = prod_test.to(device)\n",
        "            runtime_test = runtime_test.to(device)\n",
        "\n",
        "            outputs = model(x_test, prod_test, runtime_test)  # updated forward pass\n",
        "            probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
        "            all_probs.append(probs)\n",
        "            all_true.append(y_test.cpu().numpy())\n",
        "\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            correct += (preds == y_test).sum().item()\n",
        "            total += y_test.size(0)\n",
        "\n",
        "    accuracy = correct / total\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # --- Cosine-based evaluation ---\n",
        "    y_probs = np.vstack(all_probs)\n",
        "    y_true = np.concatenate(all_true)\n",
        "\n",
        "    precision = precision_at_k_cosine(y_true, y_probs, movie_db_vectors, k, threshold)\n",
        "    recall = recall_at_k_cosine(y_true, y_probs, movie_db_vectors, k, threshold)\n",
        "    f1 = f1_at_k(precision, recall)\n",
        "    ndcg = ndcg_cosine_at_k(y_true, y_probs, movie_db_vectors, k, threshold)\n",
        "\n",
        "    print(f\"Precision@{k}: {precision:.4f}\")\n",
        "    print(f\"Recall@{k}: {recall:.4f}\")\n",
        "    print(f\"F1@{k}: {f1:.4f}\")\n",
        "    print(f\"NDCG@{k}: {ndcg:.4f}\")\n",
        "\n",
        "    return accuracy, precision, recall, f1, ndcg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMjMdhnxnMFc",
        "outputId": "974b89e6-7b4a-4a71-b569-2cfab1ee6f9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Training Set Metrics ---\n",
            "Accuracy: 0.9103\n",
            "Precision@10: 0.2855\n",
            "Recall@10: 0.9937\n",
            "F1@10: 0.4435\n",
            "NDCG@10: 0.8746\n",
            "\n",
            "--- Test Set Metrics ---\n",
            "Accuracy: 0.8447\n",
            "Precision@10: 0.2660\n",
            "Recall@10: 0.9515\n",
            "F1@10: 0.4158\n",
            "NDCG@10: 0.8190\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(0.8446601941747572,\n",
              " 0.2660194174757282,\n",
              " 0.9514563106796117,\n",
              " 0.4157879252411701,\n",
              " 0.8190156580641321)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"\\n--- Training Set Metrics ---\")\n",
        "evaluate_model(model, train_loader, device, movie_db_vectors, k=10)\n",
        "\n",
        "print(\"\\n--- Test Set Metrics ---\")\n",
        "evaluate_model(model, test_loader, device, movie_db_vectors,k=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOPglKyPnqFM"
      },
      "source": [
        "### Preparing Movie Embedding Matrix for Top-K Recommendation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWyhZM1wnVkB"
      },
      "outputs": [],
      "source": [
        "\n",
        "index_to_movie_id = {i: movie_id for movie_id, i in movie_id_to_idx.items()}\n",
        "\n",
        "# Get the dimension of your full vector (Word2Vec + features)\n",
        "embedding_dim = len(df_small_ratings['combined_vector'].iloc[0])\n",
        "\n",
        "# Initialize the movie embedding matrix\n",
        "movie_embedding_matrix = np.zeros((len(movie_id_list), embedding_dim))\n",
        "\n",
        "# Fill it using the combined_vector\n",
        "for row in df_small_ratings.itertuples():\n",
        "    idx = movie_id_to_idx[row.movieId]\n",
        "    movie_embedding_matrix[idx] = row.combined_vector\n",
        "\n",
        "movie_id_to_title = df_movies_and_keywords.set_index('movieId')['original_title'].to_dict()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARcGgo4CntZW"
      },
      "source": [
        "### Generating Top K Movie Recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jy9urj9PnXyt",
        "outputId": "371d68bd-0ab2-4116-9ff7-4540e825bd21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Sample 73 ===\n",
            "Ground Truth: One Night at McCool's\n",
            "Top-10 Predictions:\n",
            "1. One Night at McCool's (cosine: 1.000)\n",
            "2. The Killing (cosine: 0.852)\n",
            "3. The Garden of Eden (cosine: 0.777)\n",
            "4. Fever Pitch (cosine: 0.709)\n",
            "5. Rush Hour (cosine: 0.800)\n",
            "6. Taxi 4 (cosine: 0.853)\n",
            "7. Bandyta (cosine: 0.779)\n",
            "8. In the Mouth of Madness (cosine: 0.793)\n",
            "9. While You Were Sleeping (cosine: 0.720)\n",
            "10. La science des rêves (cosine: 0.771)\n",
            "\n",
            "=== Sample 24 ===\n",
            "Ground Truth: Back to the Future Part II\n",
            "Top-10 Predictions:\n",
            "1. Back to the Future Part II (cosine: 1.000)\n",
            "2. Back to the Future (cosine: 0.934)\n",
            "3. Back to the Future Part III (cosine: 0.868)\n",
            "4. A Nightmare on Elm Street (cosine: 0.778)\n",
            "5. Sommersturm (cosine: 0.797)\n",
            "6. License to Wed (cosine: 0.721)\n",
            "7. Cousin, Cousine (cosine: 0.738)\n",
            "8. Tuya de hun shi (cosine: 0.768)\n",
            "9. Meet the Parents (cosine: 0.831)\n",
            "10. Say Anything... (cosine: 0.860)\n",
            "\n",
            "=== Sample 58 ===\n",
            "Ground Truth: Little Buddha\n",
            "Top-10 Predictions:\n",
            "1. The Grapes of Wrath (cosine: 0.748)\n",
            "2. Longitude (cosine: 0.741)\n",
            "3. Barry Lyndon (cosine: 0.780)\n",
            "4. Avalon (cosine: 0.707)\n",
            "5. Reign Over Me (cosine: 0.775)\n",
            "6. Ultimo tango a Parigi (cosine: 0.717)\n",
            "7. Harry Potter and the Prisoner of Azkaban (cosine: 0.769)\n",
            "8. A Clockwork Orange (cosine: 0.784)\n",
            "9. Titanic (cosine: 0.774)\n",
            "10. Dead Man (cosine: 0.741)\n",
            "\n",
            "=== Sample 94 ===\n",
            "Ground Truth: El otro lado de la cama\n",
            "Top-10 Predictions:\n",
            "1. El otro lado de la cama (cosine: 1.000)\n",
            "2. Cousin, Cousine (cosine: 0.864)\n",
            "3. Trois couleurs : Rouge (cosine: 0.815)\n",
            "4. And Then There Were None (cosine: 0.785)\n",
            "5. Delicatessen (cosine: 0.744)\n",
            "6. The Anniversary (cosine: 0.783)\n",
            "7. Sous le Sable (cosine: 0.810)\n",
            "8. Jack & Sarah (cosine: 0.835)\n",
            "9. Cat on a Hot Tin Roof (cosine: 0.813)\n",
            "10. The Killing (cosine: 0.815)\n",
            "\n",
            "=== Sample 90 ===\n",
            "Ground Truth: Monsoon Wedding\n",
            "Top-10 Predictions:\n",
            "1. Monsoon Wedding (cosine: 1.000)\n",
            "2. The Prisoner of Zenda (cosine: 0.701)\n",
            "3. Madagascar (cosine: 0.622)\n",
            "4. Terminator 3: Rise of the Machines (cosine: 0.671)\n",
            "5. There's Only One Jimmy Grimble (cosine: 0.764)\n",
            "6. Antz (cosine: 0.750)\n",
            "7. The Dark (cosine: 0.810)\n",
            "8. Buck Rogers in the 25th Century (cosine: 0.589)\n",
            "9. 8 Mile (cosine: 0.745)\n",
            "10. Revolutionary Road (cosine: 0.890)\n",
            "\n",
            "=== Sample 92 ===\n",
            "Ground Truth: Le beau mariage\n",
            "Top-10 Predictions:\n",
            "1. Le beau mariage (cosine: 1.000)\n",
            "2. La Cité des Enfants Perdus (cosine: 0.735)\n",
            "3. License to Wed (cosine: 0.709)\n",
            "4. Paper Man (cosine: 0.758)\n",
            "5. 三枪拍案惊奇 (cosine: 0.949)\n",
            "6. Bring It On (cosine: 0.625)\n",
            "7. La vita è bella (cosine: 0.730)\n",
            "8. 1984 (cosine: 0.744)\n",
            "9. Anatomie de l'enfer (cosine: 0.729)\n",
            "10. Nosferatu, eine Symphonie des Grauens (cosine: 0.654)\n",
            "\n",
            "=== Sample 62 ===\n",
            "Ground Truth: Knallhart\n",
            "Top-10 Predictions:\n",
            "1. Knallhart (cosine: 1.000)\n",
            "2. 48 Hrs. (cosine: 0.797)\n",
            "3. Sleepless in Seattle (cosine: 0.774)\n",
            "4. Back to the Future Part II (cosine: 0.749)\n",
            "5. We Own the Night (cosine: 0.797)\n",
            "6. La science des rêves (cosine: 0.797)\n",
            "7. Loose Screws (cosine: 0.700)\n",
            "8. The Goddess (cosine: 0.665)\n",
            "9. 5 Card Stud (cosine: 0.756)\n",
            "10. EVA (cosine: 0.562)\n",
            "\n",
            "=== Sample 43 ===\n",
            "Ground Truth: Sabrina\n",
            "Top-10 Predictions:\n",
            "1. 5 Card Stud (cosine: 0.737)\n",
            "2. We're No Angels (cosine: 0.746)\n",
            "3. 48 Hrs. (cosine: 0.765)\n",
            "4. Downhill Racer (cosine: 0.684)\n",
            "5. Star Trek V: The Final Frontier (cosine: 0.691)\n",
            "6. Will Penny (cosine: 0.621)\n",
            "7. Houseboat (cosine: 0.854)\n",
            "8. Hustle (cosine: 0.753)\n",
            "9. Union Station (cosine: 0.711)\n",
            "10. Star Trek: Generations (cosine: 0.700)\n",
            "\n",
            "=== Sample 35 ===\n",
            "Ground Truth: No Reservations\n",
            "Top-10 Predictions:\n",
            "1. Lili Marleen (cosine: 0.783)\n",
            "2. Nosferatu, eine Symphonie des Grauens (cosine: 0.741)\n",
            "3. Last Days (cosine: 0.765)\n",
            "4. Fools Rush In (cosine: 0.816)\n",
            "5. Terminator 3: Rise of the Machines (cosine: 0.690)\n",
            "6. Halloween (cosine: 0.680)\n",
            "7. The Dreamers (cosine: 0.846)\n",
            "8. Carry On Cowboy (cosine: 0.639)\n",
            "9. The Beach (cosine: 0.778)\n",
            "10. Dread (cosine: 0.732)\n",
            "\n",
            "=== Sample 11 ===\n",
            "Ground Truth: ...Più forte ragazzi!\n",
            "Top-10 Predictions:\n",
            "1. ...Più forte ragazzi! (cosine: 1.000)\n",
            "2. The Bourne Supremacy (cosine: 0.842)\n",
            "3. High Noon (cosine: 0.759)\n",
            "4. Local Color (cosine: 0.625)\n",
            "5. Hairspray (cosine: 0.715)\n",
            "6. Зеркало (cosine: 0.704)\n",
            "7. Galaxy Quest (cosine: 0.741)\n",
            "8. Addicted to Love (cosine: 0.716)\n",
            "9. L'Homme de Rio (cosine: 0.854)\n",
            "10. Nell (cosine: 0.692)\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "model.eval()\n",
        "all_probs = []\n",
        "all_true = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x_batch, y_batch, prod_batch, runtime_batch in test_loader:\n",
        "        x_batch = x_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "        prod_batch = prod_batch.to(device)\n",
        "        runtime_batch = runtime_batch.to(device)\n",
        "\n",
        "        logits = model(x_batch, prod_batch, runtime_batch)\n",
        "        probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
        "        all_probs.append(probs)\n",
        "        all_true.append(y_batch.cpu().numpy())\n",
        "\n",
        "# Flatten predictions and labels\n",
        "y_probs = np.vstack(all_probs)\n",
        "y_true = np.concatenate(all_true)\n",
        "\n",
        "# Sample 10 random predictions\n",
        "sample_indices = random.sample(range(len(y_true)), 10)\n",
        "\n",
        "for idx in sample_indices:\n",
        "    true_idx = y_true[idx]\n",
        "    true_movie_id = index_to_movie_id[true_idx]\n",
        "    true_title = movie_id_to_title.get(true_movie_id, \"Unknown\")\n",
        "    true_vec = movie_embedding_matrix[true_idx]\n",
        "\n",
        "    # Top-10 predictions\n",
        "    top_k = y_probs[idx].argsort()[-10:][::-1]\n",
        "    top_movie_ids = [index_to_movie_id[i] for i in top_k]\n",
        "    top_titles = [movie_id_to_title.get(mid, \"Unknown\") for mid in top_movie_ids]\n",
        "\n",
        "    print(f\"\\n=== Sample {idx} ===\")\n",
        "    print(f\"Ground Truth: {true_title}\")\n",
        "    print(\"Top-10 Predictions:\")\n",
        "\n",
        "    for rank, pred_idx in enumerate(top_k, 1):\n",
        "        pred_movie_id = index_to_movie_id[pred_idx]\n",
        "        pred_title = movie_id_to_title.get(pred_movie_id, \"Unknown\")\n",
        "        pred_vec = movie_embedding_matrix[pred_idx]\n",
        "\n",
        "        cos_sim = cosine_similarity([true_vec], [pred_vec])[0][0]\n",
        "        print(f\"{rank}. {pred_title} (cosine: {cos_sim:.3f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLXsfrjdnZF9"
      },
      "source": [
        "# LSTM with Triplet Loss Margin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XzRMrPeLb1M"
      },
      "source": [
        "## Preparing Train-Test Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqiv9drLT_X3"
      },
      "source": [
        "### Preparing Input Data for LSTM with Triplet Loss\n",
        "\n",
        "To train our LSTM-based recommendation model with triplet loss, we structure each user’s watch history using a sliding window. For every user, we extract recent movie sequences of fixed length (`max_len`) as input, with the next movie serving as the positive example.\n",
        "\n",
        "To train the model to distinguish relevant from irrelevant content, we also sample negative movies the user hasn't watched. These help the model learn to pull the user closer to the positive movie and push away the negatives in the embedding space.\n",
        "\n",
        "We further enrich each sample with categorical features like production company and runtime category, which are embedded and fed alongside the sequence to improve context-aware learning.\n",
        "\n",
        "\n",
        "#### Example Representation of Data\n",
        "\n",
        "| userId | x_seq (prev 5 movies)    | pos_vec (next) | neg_vecs (5 sampled)   | prod_id | runtime_id |\n",
        "|--------|---------------------------|----------------|-------------------------|---------|------------|\n",
        "| 001    | [m1, m2, m3, m4, m5]      | m6             | [m20, m34, m50, m77, m9]| 22   | 1      |\n",
        "| 002    | [m4, m5, m6, m7, m8]      | m9             | [m12, m14, m60, m88, m2]| 223  | 2     |\n",
        "\n",
        "This preprocessing ensures that the model learns to position the user embedding closer to relevant (positive) movies and farther from irrelevant (negative) ones within the same embedding space.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQdSTNjFgckq"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "max_len = 5  # Number of previous movies to consider in the input sequence\n",
        "neg_sample_size = 5  # Number of negative samples for each training example\n",
        "min_required = max_len + 1  # Minimum interactions required per user\n",
        "X_seq, pos_vecs, neg_vecs = [], [], []  # Lists to store training triplets\n",
        "prod_ids_seq, runtime_ids_seq = [], []  # Store categorical features for each training sample\n",
        "\n",
        "# Group the dataset by user\n",
        "grouped = df_small_ratings.groupby('userId')\n",
        "\n",
        "# Filter users who have enough interactions to form at least one sequence\n",
        "filtered_users = [uid for uid, group in grouped if len(group) >= min_required]\n",
        "\n",
        "# Iterate through each user group\n",
        "for uid, group in df_small_ratings.groupby('userId'):\n",
        "    if uid not in filtered_users:\n",
        "        continue  # Skip users with too few interactions\n",
        "\n",
        "    group = group.sort_values('date_time')  # Sort interactions chronologically\n",
        "    vectors = group['combined_vector'].tolist()  # List of movie embedding vectors\n",
        "    movie_ids = group['movieId'].tolist()  # Corresponding movie IDs\n",
        "    prod_ids = group['prod_id'].tolist()  # Production company IDs\n",
        "    runtime_ids = group['runtime_id'].tolist()  # Runtime category IDs\n",
        "\n",
        "    # Iterate through each time step starting from the second interaction\n",
        "    for i in range(1, len(vectors)):\n",
        "        start = max(0, i - max_len)  # Determine the window of past interactions\n",
        "        x_seq = vectors[start:i]  # Extract past movie vectors\n",
        "        x_padded = [np.zeros_like(x_seq[0])] * (max_len - len(x_seq)) + x_seq  # Left-pad to fixed length\n",
        "\n",
        "        target_movie_id = movie_ids[i]  # The target movie at current time step\n",
        "        pos_vec = movie_id_to_vector[target_movie_id]  # Positive sample (actual next movie vector)\n",
        "\n",
        "        # Sample negative movie vectors (not watched by this user)\n",
        "        watched_ids = set(movie_ids)\n",
        "        available_neg_ids = list(set(movie_id_to_vector.keys()) - watched_ids)\n",
        "        sampled_neg_ids = np.random.choice(available_neg_ids, size=neg_sample_size, replace=False)\n",
        "        sampled_neg_vecs = [movie_id_to_vector[mid] for mid in sampled_neg_ids]\n",
        "\n",
        "        # Append training sample: input sequence, positive and negative vectors, categorical features\n",
        "        X_seq.append(np.array(x_padded, dtype=np.float32))\n",
        "        pos_vecs.append(pos_vec)\n",
        "        neg_vecs.append(np.array(sampled_neg_vecs, dtype=np.float32))\n",
        "        prod_ids_seq.append(prod_ids[i])\n",
        "        runtime_ids_seq.append(runtime_ids[i])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgQi8i4UU2kG"
      },
      "source": [
        "### Splitting Train-Test Data\n",
        "We split the data into training and testing sets (80/20) to ensure the model learns from historical user interactions while evaluating its performance on unseen sequences and associated movie features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIvMwI5Lpqq3"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, pos_train, pos_test, neg_train, neg_test, prod_train, prod_test, runtime_train, runtime_test = train_test_split(\n",
        "    X_seq, pos_vecs, neg_vecs, prod_ids_seq, runtime_ids_seq, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sk_j_PvVUFJ"
      },
      "source": [
        "### Creating Custom DataLoader\n",
        "To prepare the data for training with triplet loss, we define a custom PyTorch dataset that returns five components for each sample: a padded sequence of movie embeddings representing a user’s viewing history, the embedding of the actual next movie watched (positive sample), several embeddings of movies the user has not seen (negative samples), and categorical identifiers for production company and runtime. These components are bundled into a `TripletDataset` and loaded into PyTorch `DataLoader`s to facilitate batch-wise training and evaluation. This format ensures that each training step has the necessary contrastive signals to teach the model which movies are more relevant to a user’s preferences.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8CExIrpl3E8",
        "outputId": "207ec64d-9c07-4358-ae5a-99bf074e421b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-cb86b5b0df52>:6: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
            "  self.X_seq = torch.tensor(X_seq, dtype=torch.float32)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class TripletDataset(Dataset):\n",
        "    def __init__(self, X_seq, pos_vecs, neg_vecs, prod_ids, runtime_ids):\n",
        "        self.X_seq = torch.tensor(X_seq, dtype=torch.float32)\n",
        "        self.pos_vecs = torch.tensor(pos_vecs, dtype=torch.float32)\n",
        "        self.neg_vecs = torch.tensor(neg_vecs, dtype=torch.float32)\n",
        "        self.prod_ids = torch.tensor(prod_ids, dtype=torch.long)\n",
        "        self.runtime_ids = torch.tensor(runtime_ids, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X_seq)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (\n",
        "            self.X_seq[idx],        # [seq_len, input_dim]\n",
        "            self.pos_vecs[idx],     # [embedding_dim]\n",
        "            self.neg_vecs[idx],     # [neg_sample_size, embedding_dim]\n",
        "            self.prod_ids[idx],     # scalar (int)\n",
        "            self.runtime_ids[idx],  # scalar (int)\n",
        "        )\n",
        "\n",
        "\n",
        "train_dataset = TripletDataset(X_train, pos_train, neg_train, prod_train, runtime_train)\n",
        "test_dataset  = TripletDataset(X_test,  pos_test,  neg_test,  prod_test,  runtime_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YqC4CltLl4R"
      },
      "source": [
        "## LSTM Triplet Loss Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOutTi6QMHK0"
      },
      "source": [
        "We use an **LSTM-based model** to capture the temporal sequence of user interactions and learn personalized user representations based on their past watched movies. Unlike matrix factorization or static models like NCF that assume user preferences are fixed, our approach acknowledges that user interests evolve over time.\n",
        "\n",
        "The LSTM processes each user’s movie-watching history in chronological order, encoding not only the individual movie features but also the context and order of consumption. We enrich this with additional movie-level categorical features (production company, runtime category) using embedding layers to help the model capture nuanced user preferences.\n",
        "\n",
        "By training the model using **triplet loss**, it learns to project each user sequence into an embedding space such that the next movie the user watched (positive sample) is closer to the user vector than randomly sampled movies (negative samples). This way, the model learns discriminative temporal representations that support more personalized and accurate ranking-based recommendations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opSjjKdYl90W"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class UserLSTMEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, num_prods, num_runtimes, hidden_dim=64, emb_dim=16, out_dim=103, dropout_rate=0.3):\n",
        "        super().__init__()\n",
        "\n",
        "        # LSTM layer to model the sequential dependencies in a user's movie history\n",
        "        # input_dim: size of each movie vector (W2V + numeric features = 103)\n",
        "        # hidden_dim: dimension of the output hidden state from LSTM\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "        # Embedding layers for categorical features\n",
        "        # emb_dim: size of the learnable embedding vectors for each category\n",
        "        self.prod_emb = nn.Embedding(num_prods, emb_dim)       # production company\n",
        "        self.runtime_emb = nn.Embedding(num_runtimes, emb_dim) # runtime category\n",
        "\n",
        "        # Concatenate: LSTM hidden state + prod_emb + runtime_emb\n",
        "        concat_dim = hidden_dim + emb_dim * 2\n",
        "\n",
        "        # Dropout layer to reduce overfitting during training\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "        # Fully connected layers to project combined feature into embedding space\n",
        "        self.fc1 = nn.Linear(concat_dim, 128)  # Intermediate projection to 128-dim\n",
        "        self.relu = nn.ReLU()                 # Non-linear activation\n",
        "        self.fc2 = nn.Linear(128, out_dim)    # Final output vector (same size as movie embeddings)\n",
        "\n",
        "    def forward(self, x_seq, prod_id, runtime_id):\n",
        "        # LSTM returns final hidden state h_n: [1, batch, hidden_dim]\n",
        "        _, (h_n, _) = self.lstm(x_seq)\n",
        "        lstm_out = h_n.squeeze(0)  # Reshape to [batch, hidden_dim]\n",
        "\n",
        "        # Look up embeddings for categorical features\n",
        "        prod_vec = self.prod_emb(prod_id)       # [batch, emb_dim]\n",
        "        runtime_vec = self.runtime_emb(runtime_id)  # [batch, emb_dim]\n",
        "\n",
        "        # Concatenate all features into one combined vector\n",
        "        combined = torch.cat([lstm_out, prod_vec, runtime_vec], dim=1)\n",
        "\n",
        "        # Apply dropout and feedforward layers\n",
        "        combined = self.dropout(combined)\n",
        "        combined = self.relu(self.fc1(combined))\n",
        "        out = self.fc2(combined)  # Final output: [batch, out_dim]\n",
        "\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APitgVe5NhQh"
      },
      "source": [
        "### Training with Triplet Margin Loss for LSTM Recommendation Model\n",
        "\n",
        "The `train_triplet_lstm_model()` function trains an LSTM-based recommendation model using triplet margin loss. It learns user embeddings from watch history sequences and movie metadata (production company and runtime), encouraging the user vector to be closer to a positive movie than to a negative one by a defined margin.\n",
        "\n",
        "During training, the LSTM processes sequences of movie embeddings, and categorical features are embedded and concatenated with the LSTM output. The triplet loss guides the model to learn a meaningful distance metric, penalizing cases where the positive is not sufficiently closer than the negative.\n",
        "\n",
        "Training accuracy is tracked by how often the user vector is more similar to the positive than the negative movie, reflecting how well the model ranks relevant content. This ranking-based approach aligns with real-world recommendation tasks where relative preferences matter more than exact classification.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1qpyZcAmE3n"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def train_triplet_lstm_model(model, train_loader, device, epochs, lr, margin=0.3):\n",
        "    # Adam optimizer for efficient gradient updates\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # Triplet margin loss: encourages anchor (user_vec) to be closer to pos_vec than neg_vec by at least the margin\n",
        "    loss_fn = nn.TripletMarginLoss(margin=margin)\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        total_samples = 0\n",
        "        correct = 0  # for monitoring similarity comparisons\n",
        "\n",
        "        for x_seq, pos_vec, neg_vecs, prod_ids, runtime_ids in train_loader:\n",
        "            x_seq = x_seq.to(device)\n",
        "            pos_vec = pos_vec.to(device)\n",
        "            neg_vec = neg_vecs[:, 0, :].to(device)  # Use only the first negative sample for training\n",
        "            prod_ids = prod_ids.to(device)\n",
        "            runtime_ids = runtime_ids.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass through the LSTM encoder with categorical embeddings\n",
        "            user_vec = model(x_seq, prod_ids, runtime_ids)\n",
        "\n",
        "            # Compute triplet loss\n",
        "            loss = loss_fn(user_vec, pos_vec, neg_vec)\n",
        "\n",
        "            # Backpropagation\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * x_seq.size(0)\n",
        "            total_samples += x_seq.size(0)\n",
        "\n",
        "            # --- Compute similarity-based \"accuracy\" ---\n",
        "            # Normalize embeddings for cosine similarity\n",
        "            user_norm = F.normalize(user_vec, dim=1)\n",
        "            pos_norm = F.normalize(pos_vec, dim=1)\n",
        "            neg_norm = F.normalize(neg_vec, dim=1)\n",
        "\n",
        "            # Compute cosine similarity (dot product of normalized vectors)\n",
        "            sim_pos = (user_norm * pos_norm).sum(dim=1)  # similarity between user and positive movie\n",
        "            sim_neg = (user_norm * neg_norm).sum(dim=1)  # similarity between user and negative movie\n",
        "\n",
        "            # Accuracy: how often the model correctly scores positive higher than negative\n",
        "            correct += (sim_pos > sim_neg).sum().item()\n",
        "\n",
        "        avg_loss = total_loss / total_samples\n",
        "        accuracy = correct / total_samples\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{epochs} - Loss: {avg_loss:.4f} - Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAzU-RrOPPVN"
      },
      "source": [
        "### Model Training\n",
        "\n",
        "Training accuracy refers to the percentage of triplets where cosine similarity(user, positive) > cosine similarity(user, negative)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ly_ly_0KnNux",
        "outputId": "15620c8e-669d-4c72-ed0f-6b926fb5fba5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 - Loss: 0.0828 - Accuracy: 0.8903\n",
            "Epoch 2/10 - Loss: 0.0599 - Accuracy: 0.9252\n",
            "Epoch 3/10 - Loss: 0.0506 - Accuracy: 0.9402\n",
            "Epoch 4/10 - Loss: 0.0448 - Accuracy: 0.9484\n",
            "Epoch 5/10 - Loss: 0.0400 - Accuracy: 0.9548\n",
            "Epoch 6/10 - Loss: 0.0370 - Accuracy: 0.9599\n",
            "Epoch 7/10 - Loss: 0.0342 - Accuracy: 0.9624\n",
            "Epoch 8/10 - Loss: 0.0317 - Accuracy: 0.9658\n",
            "Epoch 9/10 - Loss: 0.0298 - Accuracy: 0.9680\n",
            "Epoch 10/10 - Loss: 0.0289 - Accuracy: 0.9698\n"
          ]
        }
      ],
      "source": [
        "# Set Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize the LSTM model with embedding layers for categorical features\n",
        "model = UserLSTMEncoder(\n",
        "    input_dim=combined_vector.shape[1],  # input size of each movie vector\n",
        "    num_prods=num_prods,                # number of unique production companies\n",
        "    num_runtimes=num_runtimes,          # number of unique runtime categories\n",
        "    emb_dim=16,                         # size of each categorical embedding\n",
        "    hidden_dim=64,                      # hidden size of LSTM\n",
        "    out_dim=103                         # final output embedding size for user vector\n",
        ").to(device)\n",
        "\n",
        "# Train the model using triplet margin loss\n",
        "train_triplet_lstm_model(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    device=device,\n",
        "    epochs=10,           # number of training epochs\n",
        "    lr=0.001             # learning rate\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lb2O9_yOPINR"
      },
      "source": [
        "### Defining Evaluation Metrics Functions\n",
        "In this recommendation setup, our goal is not to predict the exact next movie a user will watch, but rather to recommend **relevant** ones.\n",
        "\n",
        "We modify standard metrics (Precision@K, Recall@K, F1, NDCG) to use **cosine similarity** instead of exact ID matching. This allows us to reward predictions that are semantically close to the ground truth movie—even if the IDs differ—making our evaluation more flexible and aligned with real-world recommendation goals."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIeJRMClySye"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Computes precision@k based on cosine similarity\n",
        "def precision_at_k_cosine(y_true, y_probs, movie_db_vectors, k=10, threshold=0.8):\n",
        "    total_hits = 0\n",
        "\n",
        "    for i in range(len(y_true)):\n",
        "        true_vec = movie_db_vectors[y_true[i]]  # Ground-truth movie vector\n",
        "        top_k = y_probs[i].argsort()[-k:][::-1]  # Top-k predicted indices\n",
        "\n",
        "        hits = 0\n",
        "        for pred_idx in top_k:\n",
        "            pred_vec = movie_db_vectors[pred_idx]\n",
        "            # If prediction is similar enough to ground truth\n",
        "            cos_sim = cosine_similarity([true_vec], [pred_vec])[0][0]\n",
        "            if cos_sim >= threshold:\n",
        "                hits += 1\n",
        "\n",
        "        total_hits += hits / k  # Compute precision for this sample\n",
        "\n",
        "    return total_hits / len(y_true)  # Average precision over all samples\n",
        "\n",
        "# Computes recall@k based on cosine similarity\n",
        "def recall_at_k_cosine(y_true, y_probs, movie_db_vectors, k=10, threshold=0.8):\n",
        "    hits = 0\n",
        "\n",
        "    for i in range(len(y_true)):\n",
        "        true_vec = movie_db_vectors[y_true[i]]\n",
        "        top_k = y_probs[i].argsort()[-k:][::-1]\n",
        "\n",
        "        for pred_idx in top_k:\n",
        "            pred_vec = movie_db_vectors[pred_idx]\n",
        "            cos_sim = cosine_similarity([true_vec], [pred_vec])[0][0]\n",
        "            if cos_sim >= threshold:\n",
        "                hits += 1\n",
        "                break  # Only need one match to count as a hit\n",
        "\n",
        "    return hits / len(y_true)  # Proportion of samples with at least one correct prediction\n",
        "\n",
        "# Computes F1 score from precision and recall\n",
        "def f1_at_k(precision, recall):\n",
        "    if precision + recall == 0:\n",
        "        return 0.0\n",
        "    return 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "# Compute DCG (Discounted Cumulative Gain)\n",
        "def dcg_at_k(ranked_list, true_label, k=10):\n",
        "    for i in range(min(k, len(ranked_list))):\n",
        "        if ranked_list[i] == true_label:\n",
        "            return 1 / np.log2(i + 2)  # Log base 2, offset by 2 to avoid log(1)\n",
        "    return 0.0\n",
        "\n",
        "# Computes NDCG@k using cosine similarity\n",
        "def ndcg_cosine_at_k(y_true, y_probs, movie_db_vectors, k=10, threshold=0.8):\n",
        "    total_ndcg = 0.0\n",
        "\n",
        "    for i in range(len(y_true)):\n",
        "        true_vec = movie_db_vectors[y_true[i]]\n",
        "        top_k_indices = y_probs[i].argsort()[-k:][::-1]  # Top-k predicted indices\n",
        "\n",
        "        # Assign relevance based on similarity threshold\n",
        "        relevance_scores = []\n",
        "        for pred_idx in top_k_indices:\n",
        "            pred_vec = movie_db_vectors[pred_idx]\n",
        "            sim = cosine_similarity([true_vec], [pred_vec])[0][0]\n",
        "            relevance = 1 if sim >= threshold else 0\n",
        "            relevance_scores.append(relevance)\n",
        "\n",
        "        # Calculate DCG\n",
        "        dcg = 0.0\n",
        "        for rank, rel in enumerate(relevance_scores):\n",
        "            if rel:\n",
        "                dcg += 1 / np.log2(rank + 2)\n",
        "\n",
        "        # Calculate IDCG (ideal DCG)\n",
        "        ideal_rels = sorted(relevance_scores, reverse=True)\n",
        "        idcg = 0.0\n",
        "        for rank, rel in enumerate(ideal_rels):\n",
        "            if rel:\n",
        "                idcg += 1 / np.log2(rank + 2)\n",
        "\n",
        "        ndcg = dcg / idcg if idcg > 0 else 0.0\n",
        "        total_ndcg += ndcg\n",
        "\n",
        "    return total_ndcg / len(y_true)  # Average NDCG across all samples\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3-tMxLJPtn0"
      },
      "source": [
        "### Evaluation\n",
        "\n",
        "In this evaluation, we assess the effectiveness of our LSTM-based model for movie recommendation by measuring how well it retrieves relevant movies, rather than predicting the exact next movie a user will watch. The model learns user representations based on their historical watch sequences and then ranks all movies in the database according to their similarity to the predicted user embedding.\n",
        "\n",
        "To evaluate this, we use cosine similarity to compare the user embedding with every movie vector in the database, generating a ranked list of recommendations. We then locate the ground truth movie (the actual next movie the user watched) within this list. If the predicted ranking places the correct movie—or a semantically similar one—among the top results, the model is considered effective.\n",
        "\n",
        "We report several metrics. Accuracy reflects how often the correct movie is ranked at the top. Precision@K and Recall@K evaluate whether the model retrieves relevant movies within the top K recommendations based on cosine similarity. F1@K combines precision and recall to give a balanced measure, while NDCG@K accounts for the position of the correct movie in the ranking, rewarding higher placements more heavily.\n",
        "\n",
        "This evaluation design prioritizes semantic relevance over exact matches, aligning better with real-world recommendation goals where offering related or suitable content often matters more than predicting the precise item.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9q-yj4my5VR"
      },
      "outputs": [],
      "source": [
        "def evaluate_lstm_ranking_model(model, test_loader, movie_db_vectors, movie_id_to_vector, movie_id_list, device, k=10, threshold=0.8):\n",
        "    model.eval()\n",
        "    all_y_true, all_y_probs = [], []\n",
        "    correct_count, total_count = 0, 0\n",
        "\n",
        "    # Stack movie vectors into a matrix and move to the correct device\n",
        "    movie_db_matrix = np.stack([np.array(movie_id_to_vector[mid], dtype=np.float32) for mid in movie_id_list])\n",
        "    movie_db_tensor = torch.tensor(movie_db_matrix, dtype=torch.float32).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_seq_batch, pos_vec_batch, _, prod_batch, runtime_batch in test_loader:\n",
        "            # Move batch data to the same device as the model\n",
        "            x_seq_batch = x_seq_batch.to(device)\n",
        "            pos_vec_batch = pos_vec_batch.to(device)\n",
        "            prod_batch = prod_batch.to(device)\n",
        "            runtime_batch = runtime_batch.to(device)\n",
        "\n",
        "            # Forward pass to get the user representation\n",
        "            user_vec_batch = model(x_seq_batch, prod_batch, runtime_batch)\n",
        "\n",
        "            # Compute cosine similarities between user vec and every movie in the DB\n",
        "            sims = cosine_similarity(user_vec_batch.cpu(), movie_db_tensor.cpu())\n",
        "\n",
        "            for i in range(len(pos_vec_batch)):\n",
        "                true_vec = pos_vec_batch[i].cpu().numpy()\n",
        "\n",
        "                # Try to find the index of the ground truth movie in the full movie DB\n",
        "                matched_index = -1\n",
        "                for idx, mid in enumerate(movie_id_list):\n",
        "                    if np.allclose(movie_id_to_vector[mid], true_vec, atol=1e-5):\n",
        "                        matched_index = idx\n",
        "                        break\n",
        "\n",
        "                # If a match was found, record ground truth and predictions\n",
        "                if matched_index != -1:\n",
        "                    all_y_true.append(matched_index)\n",
        "                    all_y_probs.append(sims[i])\n",
        "\n",
        "                    # Accuracy = how often the top-1 prediction is correct\n",
        "                    pred_index = np.argmax(sims[i])\n",
        "                    if pred_index == matched_index:\n",
        "                        correct_count += 1\n",
        "                    total_count += 1\n",
        "\n",
        "    # Convert accumulated predictions and labels to arrays\n",
        "    all_y_probs = np.array(all_y_probs)\n",
        "    all_y_true = np.array(all_y_true)\n",
        "\n",
        "    # Compute metrics using cosine-based definitions\n",
        "    precision = precision_at_k_cosine(all_y_true, all_y_probs, movie_db_matrix, k=k, threshold=threshold)\n",
        "    recall = recall_at_k_cosine(all_y_true, all_y_probs, movie_db_matrix, k=k, threshold=threshold)\n",
        "    f1 = f1_at_k(precision, recall)\n",
        "    ndcg = ndcg_cosine_at_k(all_y_true, all_y_probs, movie_db_matrix, k=k, threshold=threshold)\n",
        "    accuracy = correct_count / total_count if total_count > 0 else 0.0\n",
        "\n",
        "    # Output results\n",
        "    print(f\"\\n--- Evaluation Results ---\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision@{k}: {precision:.4f}\")\n",
        "    print(f\"Recall@{k}: {recall:.4f}\")\n",
        "    print(f\"F1@{k}: {f1:.4f}\")\n",
        "    print(f\"NDCG@{k}: {ndcg:.4f}\")\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1,\n",
        "        \"ndcg\": ndcg\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwEp8JqZCsMD",
        "outputId": "2b9438ff-b9a6-4287-a3ff-626bc149f566"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Evaluation Results ---\n",
            "Accuracy: 0.0527\n",
            "Precision@10: 0.4922\n",
            "Recall@10: 0.8467\n",
            "F1@10: 0.6226\n",
            "NDCG@10: 0.6757\n",
            "\n",
            "--- Train Set Metrics ---\n",
            "{'accuracy': 0.05271182133882944, 'precision': 0.4922386289844462, 'recall': 0.8467206866371156, 'f1': 0.6225560777842516, 'ndcg': 0.6756728779756033}\n"
          ]
        }
      ],
      "source": [
        "train_metrics = evaluate_lstm_ranking_model(\n",
        "    model=model,\n",
        "    test_loader=train_loader,\n",
        "    movie_db_vectors=movie_db_vectors,\n",
        "    movie_id_to_vector=movie_id_to_vector,\n",
        "    movie_id_list=movie_id_list,\n",
        "    device=device,\n",
        "    k=10\n",
        ")\n",
        "print(\"\\n--- Train Set Metrics ---\")\n",
        "print(train_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eS8upPb-otKV",
        "outputId": "e4c6895b-73c2-4398-8158-e0135e687346"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluation Results ---\n",
            "Accuracy: 0.0519\n",
            "Precision@10: 0.4776\n",
            "Recall@10: 0.8469\n",
            "F1@10: 0.6108\n",
            "NDCG@10: 0.6674\n",
            "\n",
            "--- Test Set Metrics ---\n",
            "{'accuracy': 0.05194805194805195, 'precision': 0.47761716544324984, 'recall': 0.8468661773009599, 'f1': 0.6107707210182102, 'ndcg': 0.6673899106824986}\n"
          ]
        }
      ],
      "source": [
        "metrics = evaluate_lstm_ranking_model(\n",
        "    model=model,\n",
        "    test_loader=test_loader,\n",
        "    movie_db_vectors=movie_db_vectors,           # full matrix of movie vectors\n",
        "    movie_id_to_vector=movie_id_to_vector,       # movieId → vector\n",
        "    movie_id_list=movie_id_list,                 # ordered list of all movieIds\n",
        "    device=device,\n",
        "    k=10                                         # or any top-k value\n",
        ")\n",
        "print(\"\\n--- Test Set Metrics ---\")\n",
        "print(metrics)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EMtP8VnWdN0"
      },
      "source": [
        "## Generating Top-K Movies Recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMDUfjWnVrCe"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def display_top_k_recommendations(model, test_loader, movie_id_to_vector, movie_id_to_title, movie_id_list, device, k=10, num_samples=5):\n",
        "    model.eval()\n",
        "\n",
        "    movie_db_matrix = np.stack([np.array(movie_id_to_vector[mid], dtype=np.float32) for mid in movie_id_list])\n",
        "    movie_db_tensor = torch.tensor(movie_db_matrix, dtype=torch.float32).to(device)\n",
        "\n",
        "    all_inputs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x_seq_batch, pos_vec_batch, _, prod_batch, runtime_batch in test_loader:\n",
        "            for i in range(len(pos_vec_batch)):\n",
        "                all_inputs.append((\n",
        "                    x_seq_batch[i], pos_vec_batch[i],\n",
        "                    prod_batch[i], runtime_batch[i]\n",
        "                ))\n",
        "\n",
        "        sampled_inputs = random.sample(all_inputs, min(num_samples, len(all_inputs)))\n",
        "\n",
        "        for idx, (x_seq, pos_vec, prod_id, runtime_id) in enumerate(sampled_inputs):\n",
        "            x_seq = x_seq.unsqueeze(0).to(device)\n",
        "            pos_vec = pos_vec.unsqueeze(0).to(device)\n",
        "            prod_id = prod_id.unsqueeze(0).to(device)\n",
        "            runtime_id = runtime_id.unsqueeze(0).to(device)\n",
        "\n",
        "            user_vec = model(x_seq, prod_id, runtime_id)\n",
        "            sims = cosine_similarity(user_vec.cpu(), movie_db_tensor.cpu())[0]\n",
        "\n",
        "            true_vec = pos_vec.cpu().numpy()[0]\n",
        "            matched_movie_id = None\n",
        "            for mid, vec in movie_id_to_vector.items():\n",
        "                if np.allclose(vec, true_vec, atol=1e-5):\n",
        "                    matched_movie_id = mid\n",
        "                    break\n",
        "\n",
        "            if matched_movie_id is None:\n",
        "                continue\n",
        "\n",
        "            ground_truth_title = movie_id_to_title.get(matched_movie_id, \"Unknown\")\n",
        "            top_k_indices = sims.argsort()[::-1][:k]\n",
        "\n",
        "            print(f\"\\n=== Sample {idx + 1} ===\")\n",
        "            print(f\"Ground Truth: {ground_truth_title}\")\n",
        "            print(f\"Top-{k} Predictions:\")\n",
        "            for rank, top_idx in enumerate(top_k_indices, 1):\n",
        "                pred_mid = movie_id_list[top_idx]\n",
        "                pred_title = movie_id_to_title.get(pred_mid, \"Unknown\")\n",
        "                cos_sim = cosine_similarity([true_vec], [movie_db_matrix[top_idx]])[0][0]\n",
        "                print(f\"{rank}. {pred_title} (cosine similarity: {cos_sim:.4f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gf1sOff7V9m0",
        "outputId": "0ddc685b-f58f-4c9d-84d5-47bff4be4b9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Sample 1 ===\n",
            "Ground Truth: 48 Hrs.\n",
            "Top-10 Predictions:\n",
            "1. Strangers on a Train (cosine similarity: 0.8226)\n",
            "2. Stagecoach (cosine similarity: 0.8388)\n",
            "3. Back to the Future (cosine similarity: 0.8177)\n",
            "4. Return of the Jedi (cosine similarity: 0.7758)\n",
            "5. The Gold Rush (cosine similarity: 0.7819)\n",
            "6. The Sea Wolf (cosine similarity: 0.7675)\n",
            "7. Outland (cosine similarity: 0.7308)\n",
            "8. Steamboat Bill, Jr. (cosine similarity: 0.8294)\n",
            "9. Reservoir Dogs (cosine similarity: 0.8245)\n",
            "10. Marnie (cosine similarity: 0.8479)\n",
            "\n",
            "=== Sample 2 ===\n",
            "Ground Truth: Stellet Licht\n",
            "Top-10 Predictions:\n",
            "1. 生きる (cosine similarity: 0.8791)\n",
            "2. Close Encounters of the Third Kind (cosine similarity: 0.7568)\n",
            "3. City of Angels (cosine similarity: 0.8088)\n",
            "4. The Hours (cosine similarity: 0.9044)\n",
            "5. A Beautiful Mind (cosine similarity: 0.7878)\n",
            "6. The Notebook (cosine similarity: 0.8299)\n",
            "7. City Lights (cosine similarity: 0.7921)\n",
            "8. Airplane! (cosine similarity: 0.7096)\n",
            "9. Vertigo (cosine similarity: 0.8268)\n",
            "10. Short Cuts (cosine similarity: 0.8637)\n",
            "\n",
            "=== Sample 3 ===\n",
            "Ground Truth: La belle et la bête\n",
            "Top-10 Predictions:\n",
            "1. Azuloscurocasinegro (cosine similarity: 0.8134)\n",
            "2. Letter from an Unknown Woman (cosine similarity: 0.8056)\n",
            "3. Around the Bend (cosine similarity: 0.8058)\n",
            "4. My Life Without Me (cosine similarity: 0.8405)\n",
            "5. Definitely, Maybe (cosine similarity: 0.8376)\n",
            "6. Little Man Tate (cosine similarity: 0.8131)\n",
            "7. Alles auf Zucker! (cosine similarity: 0.8037)\n",
            "8. La belle et la bête (cosine similarity: 1.0000)\n",
            "9. Le temps qui reste (cosine similarity: 0.8230)\n",
            "10. The Bucket List (cosine similarity: 0.8208)\n",
            "\n",
            "=== Sample 4 ===\n",
            "Ground Truth: 해안선\n",
            "Top-10 Predictions:\n",
            "1. The Notebook (cosine similarity: 0.8350)\n",
            "2. Charade (cosine similarity: 0.8474)\n",
            "3. Underworld (cosine similarity: 0.8107)\n",
            "4. Argo (cosine similarity: 0.8112)\n",
            "5. Marnie (cosine similarity: 0.8531)\n",
            "6. The Boy (cosine similarity: 0.8472)\n",
            "7. The Good Shepherd (cosine similarity: 0.8716)\n",
            "8. Breakfast at Tiffany's (cosine similarity: 0.8286)\n",
            "9. Deliverance (cosine similarity: 0.8199)\n",
            "10. Django Unchained (cosine similarity: 0.7715)\n",
            "\n",
            "=== Sample 5 ===\n",
            "Ground Truth: Hibernatus\n",
            "Top-10 Predictions:\n",
            "1. Rocky II (cosine similarity: 0.6333)\n",
            "2. The Sixth Sense (cosine similarity: 0.6532)\n",
            "3. Magnolia (cosine similarity: 0.6334)\n",
            "4. Kramer vs. Kramer (cosine similarity: 0.5972)\n",
            "5. Tristana (cosine similarity: 0.6199)\n",
            "6. The Hand that Rocks the Cradle (cosine similarity: 0.6404)\n",
            "7. La leggenda del pianista sull'oceano (cosine similarity: 0.6718)\n",
            "8. Rocky (cosine similarity: 0.6439)\n",
            "9. Rain Man (cosine similarity: 0.6958)\n",
            "10. Strangers on a Train (cosine similarity: 0.6557)\n"
          ]
        }
      ],
      "source": [
        "movie_id_to_title = df_movies_and_keywords.set_index('movieId')['original_title'].to_dict()\n",
        "display_top_k_recommendations(\n",
        "    model=model,\n",
        "    test_loader=test_loader,\n",
        "    movie_id_to_vector=movie_id_to_vector,\n",
        "    movie_id_to_title=movie_id_to_title,\n",
        "    movie_id_list=movie_id_list,\n",
        "    device=device,\n",
        "    k=10,\n",
        "    num_samples=5  # How many test samples you want to print\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}